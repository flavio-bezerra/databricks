# üìà CVC Lojas - Forecasting MLOps Pipeline

Este projeto implementa um pipeline de **MLOps ponta a ponta** para previs√£o de vendas das lojas f√≠sicas da CVC. A arquitetura utiliza **Databricks**, **Unity Catalog**, **Feature Store**, e modelos de S√©ries Temporais (**Darts**) orquestrados via **MLflow**.



## üèóÔ∏è Arquitetura e Estrutura

O projeto adota uma estrutura modular, separando a l√≥gica de neg√≥cio (pacote `src`) da execu√ß√£o (Notebooks).

```text
databricks/
‚îú‚îÄ‚îÄ src/                            # üì¶ Core Package (L√≥gica Modularizada)
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/                  # Conectores JDBC & Feature Store (Liquid Clustering)
‚îÇ   ‚îú‚îÄ‚îÄ validation/                 # Pipelines de Treino, Walk-Forward & Configs
‚îÇ   ‚îî‚îÄ‚îÄ deploy/                     # Wrapper "All-in-One" para Infer√™ncia Produtiva
‚îÇ
‚îú‚îÄ‚îÄ 1_ingestao_features.ipynb       # ETL: SQL Server -> Databricks Feature Store
‚îú‚îÄ‚îÄ 2_validacao_modelos.ipynb       # Experimenta√ß√£o: Backtesting (Walk-Forward)
‚îú‚îÄ‚îÄ 3_treino_final_deploy.ipynb     # Deploy: Treino Final (2021-2025) -> Unity Catalog
‚îî‚îÄ‚îÄ 4_inferencia_recorrente.ipynb   # Produ√ß√£o: Scoring Semanal/Mensal
```

---

## üöÄ Fluxos de Trabalho (Workflows)

### 1. Ingest√£o de Dados (`src.ingestion`)
Respons√°vel por trazer dados transacionais do Azure SQL para o **Feature Store** no Unity Catalog.
* **Destaques:** Utiliza *Liquid Clustering* e remo√ß√£o de duplicatas baseada em PKs para garantir qualidade na entrada.
* **Artefato:** Tabelas Delta otimizadas em `ds_dev.cvc_val.*`.

### 2. Valida√ß√£o de Modelos (`src.validation`)
Executa uma valida√ß√£o rigorosa para escolher o melhor algoritmo.
* **Metodologia:** *Strict Walk-Forward Validation*. O modelo √© treinado e testado m√™s a m√™s no passado, sem vazamento de dados futuros.
* **Modelos Avaliados:** LightGBM, XGBoost, TFT (Temporal Fusion Transformer), N-BEATS.
* **Seguran√ßa:** Utiliza `OrdinalEncoder` com tratamento para categorias desconhecidas (novas lojas).

### 3. Treino e Deploy (`src.deploy`)
Treina a vers√£o final do modelo com dados recentes (P√≥s-Pandemia: 2021-2025) para evitar *Concept Drift*.
* **Wrapper "UnifiedForecaster":** O modelo √© encapsulado em uma classe Python customizada que cont√©m:
    * O modelo treinado (ex: LightGBM).
    * O pipeline de transforma√ß√£o (`Scalers`, `Encoders`).
    * L√≥gica autom√°tica de gera√ß√£o de datas futuras e feriados.
* **Registro:** O modelo √© salvo no Unity Catalog e promovido via Alias (`@Champion`).

### 4. Infer√™ncia Recorrente
Pipeline agendado que consome o modelo `@Champion`.
* **Resili√™ncia:** O sistema detecta automaticamente se precisa gerar o esqueleto de datas futuras (Forecast Horizon) ou se ele j√° foi fornecido.
* **Fallback:** Em caso de falha cr√≠tica, retorna um schema vazio v√°lido para n√£o quebrar jobs Spark dependentes.

---

## üõ†Ô∏è Tecnologias e Bibliotecas

* **Plataforma:** Databricks (Runtime ML)
* **Governan√ßa:** Unity Catalog (Features & Models)
* **Frameworks:**
    * `Darts` (Time Series)
    * `PySpark` & `Delta Lake`
    * `MLflow` (Tracking & Registry)
    * `Scikit-Learn` (Pipelines)

## üìã Como Executar

### Pr√©-requisitos
Certifique-se de que a pasta `src` esteja no diret√≥rio de trabalho ou instalada como biblioteca.

### Passo a Passo
1.  **Ingest√£o:** Execute `cvc_ingestao_features_validacao.ipynb` para atualizar as tabelas do Feature Store.
2.  **Valida√ß√£o (Opcional):** Execute `cvc_validacao_modelos_lojas.ipynb` se desejar testar novas arquiteturas de modelo.
3.  **Deploy:** Execute `cvc_treino_final_deploy.ipynb`. Este notebook ir√°:
    * Treinar o modelo com dados at√© `2025-12-31`.
    * Registrar o modelo no Unity Catalog.
    * Atribuir a tag **@Champion** √† nova vers√£o.
4.  **Infer√™ncia:** Execute `cvc_inferencia_recorrente.ipynb`. Ele carregar√° automaticamente a vers√£o `@Champion` e salvar√° as previs√µes na tabela de resultados.

---

## üõ°Ô∏è Robustez e Tratamento de Erros

* **Safe ID Extraction:** O sistema blinda os IDs das lojas (`CODIGO_LOJA`) para evitar que transforma√ß√µes num√©ricas corrompam identificadores (ex: "Loja 001" virar "1.0").
* **Future Skeleton:** O Wrapper √© capaz de autocompletar datas futuras caso o input contenha apenas dados hist√≥ricos.
* **Schema Enforcement:** Retornos de erro padronizados garantem que o Spark n√£o falhe por incompatibilidade de tipos.