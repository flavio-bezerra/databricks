{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c5e7727-af0f-4472-8606-2d4b2d689f02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 0. IMPORTS E SETUP ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Adiciona o diret√≥rio raiz ao path para importar os m√≥dulos 'src'\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Imports dos M√≥dulos do Projeto\n",
    "from src.validation.config import Config\n",
    "from src.validation.data import DataIngestion\n",
    "from src.validation.pipeline import ProjectPipeline\n",
    "from src.validation.trainer import ModelTrainer \n",
    "from src.deploy.wrapper import UnifiedForecaster\n",
    "\n",
    "# Bibliotecas de Modelagem e MLflow\n",
    "from darts.models import LightGBMModel\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Configura√ß√µes de Otimiza√ß√£o do Spark (Delta Lake)\n",
    "spark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.databricks.delta.autoCompact.enabled\", \"true\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6816bae9-7547-423a-8072-93cc9dff1e51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(datetime.today().strftime(\"%Y-%m-01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91ec4838-c5ed-447c-9004-bd2a36cc1a78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_final_deploy - relativedelta(months=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f187f3d1-aab3-4e90-b99a-d3c18d487f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. CONFIGURA√á√ÉO DO AMBIENTE E DATAS\n",
    "# ==============================================================================\n",
    "config = Config(spark)\n",
    "\n",
    "# [IMPORTANTE] For√ßa o nome do experimento para ser o de DEPLOY\n",
    "# Isso garante que a valida√ß√£o e o deploy fiquem no mesmo local no MLflow\n",
    "config.EXPERIMENT_NAME = \"/Workspace/Shared/data_science/projetos/cvc_curva_de_vendas_por_canal/experiments/Model_Deploy_CVC_Loja\"\n",
    "\n",
    "# Defini√ß√£o Din√¢mica das Datas (Janela de 3 Meses para Valida√ß√£o)\n",
    "# O treino final vai at√© a data configurada no widget (TRAIN_END_DATE)\n",
    "data_final_deploy = pd.to_datetime(datetime.today().strftime(\"%Y-%m-01\"))\n",
    "data_inicio_validacao = data_final_deploy - relativedelta(months=3)\n",
    "\n",
    "config.TRAIN_END_DATE = data_final_deploy\n",
    "# Atualiza config para o ModelTrainer saber onde come√ßar o teste\n",
    "config.VAL_START_DATE = data_inicio_validacao.strftime(\"%Y-%m-%d\")\n",
    "# Garante que a ingest√£o pegue at√© o √∫ltimo dia dispon√≠vel\n",
    "config.INGESTION_END = config.TRAIN_END_DATE \n",
    "\n",
    "print(f\"üìÇ EXPERIMENTO ALVO: {config.EXPERIMENT_NAME}\")\n",
    "print(f\"‚è±Ô∏è PER√çODO TOTAL DE DADOS: {config.DATA_START} at√© {config.TRAIN_END_DATE}\")\n",
    "print(f\"üîç JANELA DE TESTE (BACKTEST): {config.VAL_START_DATE} at√© {config.TRAIN_END_DATE} (√öltimos 3 meses)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f9ae8cb-fc7a-4871-bc79-eb59cd92102a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config.DATA_START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbed633e-f394-4cfd-bc32-2f3103c0fc99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. IN√çCIO DA EXECU√á√ÉO MESTRA\n",
    "# ==============================================================================\n",
    "mlflow.set_experiment(config.EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Pipeline_Completo_{config.VERSION}\") as parent_run:\n",
    "    \n",
    "    print(f\"üîó Parent Run ID: {parent_run.info.run_id}\")\n",
    "    mlflow.log_param(\"pipeline_type\", \"auto_retrain_w_quality_gate\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 3. INGEST√ÉO E PREPARA√á√ÉO\n",
    "    # ==========================================================================\n",
    "    ingestion = DataIngestion(spark, config)\n",
    "    df_spark_raw = ingestion.create_training_set()\n",
    "\n",
    "    # Filtra per√≠odo total\n",
    "    df_spark_filtered = df_spark_raw.filter(\n",
    "        (df_spark_raw.data >= config.DATA_START) & (df_spark_raw.data <= config.TRAIN_END_DATE)\n",
    "    )\n",
    "\n",
    "    # Suporte global\n",
    "    df_global_support = ingestion.get_global_support()\n",
    "    df_global_support = df_global_support[config.DATA_START : config.TRAIN_END_DATE]\n",
    "\n",
    "    # Converte para Darts\n",
    "    full_target_list, full_covariates_list = ingestion.build_darts_objects(df_spark_filtered, df_global_support)\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 4. PREPARA√á√ÉO DO PIPELINE (SCALERS)\n",
    "    # ==========================================================================\n",
    "    pipeline = ProjectPipeline()\n",
    "    val_cutoff_dt = pd.Timestamp(config.VAL_START_DATE) - pd.Timedelta(days=1)\n",
    "\n",
    "    # Fit nos dados hist√≥ricos (evita Data Leakage)\n",
    "    train_subset_for_fit = [s.drop_after(val_cutoff_dt) for s in full_target_list]\n",
    "    cov_subset_for_fit = [c.drop_after(val_cutoff_dt) for c in full_covariates_list]\n",
    "\n",
    "    print(\"‚öôÔ∏è Ajustando Scalers...\")\n",
    "    pipeline.fit(train_subset_for_fit, cov_subset_for_fit)\n",
    "\n",
    "    # Transforma base completa\n",
    "    scaled_series, scaled_covariates = pipeline.transform(full_target_list, full_covariates_list)\n",
    "    \n",
    "    train_series_static = [s.drop_after(val_cutoff_dt) for s in scaled_series]\n",
    "    train_cov_static = [c.drop_after(val_cutoff_dt) for c in scaled_covariates]\n",
    "    val_series_original = pipeline.inverse_transform(scaled_series, partial=True)\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 5. VALIDA√á√ÉO AUTOM√ÅTICA (BACKTEST)\n",
    "    # ==========================================================================\n",
    "    model_params = {\n",
    "        \"lags\": 12,\n",
    "        \"lags_future_covariates\": [0,1,2,3],\n",
    "        \"output_chunk_length\": 1,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    models_dict = {\"LightGBM_Candidate\": LightGBMModel(**model_params)}\n",
    "\n",
    "    print(f\"\\nüöÄ Executando Backtest (3 Meses)...\")\n",
    "    trainer = ModelTrainer(config, models_dict)\n",
    "    trainer.train_evaluate_walkforward(\n",
    "        train_series_static=train_series_static,\n",
    "        train_covs_static=train_cov_static,\n",
    "        full_series_scaled=scaled_series,\n",
    "        full_covariates_scaled=scaled_covariates,\n",
    "        val_series_original=val_series_original,\n",
    "        target_pipeline=pipeline\n",
    "    )\n",
    "    \n",
    "    # ==========================================================================\n",
    "    # [NOVO] 6. GATEKEEPER (TRAVA DE SEGURAN√áA)\n",
    "    # ==========================================================================\n",
    "    print(\"\\nüëÆ Verificando Qualidade do Modelo (Gatekeeper)...\")\n",
    "    \n",
    "    # A. L√™ os resultados salvos na tabela Delta pela valida√ß√£o acima\n",
    "    # Filtra apenas pela vers√£o atual do pipeline para n√£o pegar lixo antigo\n",
    "    df_results = spark.table(\"ds_dev.cvc_val.resultado_metricas_treinamento_lojas\") \\\n",
    "                      .filter(F.col(\"versao\") == config.VERSION)\n",
    "    \n",
    "    # B. Descobre qual foi o √∫ltimo m√™s validado (o m√™s mais recente)\n",
    "    # A coluna 'metrica_mes' √© string 'YYYY-MM', ent√£o o MAX funciona lexicograficamente\n",
    "    try:\n",
    "        last_month_str = df_results.select(F.max(\"metrica_mes\")).collect()[0][0]\n",
    "    except:\n",
    "        raise Exception(\"‚ùå ERRO CR√çTICO: Tabela de resultados vazia. Valida√ß√£o falhou silenciosamente?\")\n",
    "\n",
    "    if not last_month_str:\n",
    "        raise Exception(\"‚ùå ERRO: N√£o foi poss√≠vel identificar o m√™s de valida√ß√£o.\")\n",
    "\n",
    "    print(f\"   üìÖ Analisando m√™s de corte: {last_month_str}\")\n",
    "\n",
    "    # C. Calcula o RMSE especificamente para este m√™s\n",
    "    # F√≥rmula RMSE: SQRT( MEAN( (Real - Prev)^2 ) )\n",
    "    rmse_check = df_results.filter(F.col(\"metrica_mes\") == last_month_str) \\\n",
    "                           .select(F.sqrt(F.mean(F.pow(F.col(\"real\") - F.col(\"previsao\"), 2))).alias(\"rmse\")) \\\n",
    "                           .collect()[0][\"rmse\"]\n",
    "\n",
    "    # Se der Nulo (sem dados), assume erro\n",
    "    if rmse_check is None: rmse_check = 999999.0\n",
    "    \n",
    "    print(f\"   üìâ RMSE Calculado: {rmse_check:.4f}\")\n",
    "    \n",
    "    # Loga na Run Pai para auditoria\n",
    "    mlflow.log_metric(\"gatekeeper_last_month_rmse\", rmse_check)\n",
    "\n",
    "    # D. APLICA A TRAVA\n",
    "    LIMIT_RMSE = 1000000\n",
    "    \n",
    "    if rmse_check >= LIMIT_RMSE:\n",
    "        error_msg = (f\"‚õî BLOQUEIO DE DEPLOY: RMSE do √∫ltimo m√™s ({rmse_check:.2f}) \"\n",
    "                     f\"excedeu o limite aceit√°vel ({LIMIT_RMSE}). Pipeline Abortado.\")\n",
    "        # Marca a run pai como FALHA explicitamente\n",
    "        mlflow.set_tag(\"pipeline_status\", \"BLOCKED_BY_QUALITY\")\n",
    "        raise Exception(error_msg)\n",
    "    \n",
    "    print(\"‚úÖ Crit√©rio de Qualidade Aprovado! Prosseguindo para Deploy.\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 7. TREINAMENTO FINAL (FULL DATASET)\n",
    "    # ==========================================================================\n",
    "    print(\"\\nüèãÔ∏è Iniciando Treinamento Final (Full Dataset)...\")\n",
    "    final_model = LightGBMModel(**model_params)\n",
    "    final_model.fit(scaled_series, future_covariates=scaled_covariates)\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 8. REGISTRO E DEPLOY\n",
    "    # ==========================================================================\n",
    "    catalog_model_name = f\"{config.CATALOG}.{config.SCHEMA}.cvc_lojas_forecast_production\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"Deploy_Artifact_{config.VERSION}\", nested=True) as deploy_run:\n",
    "        print(f\"üíæ Registrando modelo: {catalog_model_name}\")\n",
    "        \n",
    "        # Tags de rastreabilidade\n",
    "        mlflow.set_tag(\"parent_run_id\", parent_run.info.run_id)\n",
    "        mlflow.set_tag(\"quality_check_rmse\", f\"{rmse_check:.2f}\")\n",
    "\n",
    "        # Prepara√ß√£o de Artefatos (Pipeline, Modelo, Metadados)\n",
    "        sample_ts = full_target_list[0]\n",
    "        sample_cov = full_covariates_list[0]\n",
    "        \n",
    "        training_metadata = {\n",
    "            \"static_cols_order\": [c for c in sample_ts.static_covariates.columns.tolist() if c != \"codigo_loja\"],\n",
    "            \"covariate_cols_order\": sample_cov.components.tolist(),\n",
    "            \"max_lag\": 15\n",
    "        }\n",
    "\n",
    "        pipeline_path, model_path, cov_path, meta_path = \"pipeline.pkl\", \"lgbm_model.pkl\", \"future_covariates.pkl\", \"model_metadata.pkl\"\n",
    "        with open(pipeline_path, \"wb\") as f: pickle.dump(pipeline, f)\n",
    "        with open(model_path, \"wb\") as f: pickle.dump(final_model, f)\n",
    "        with open(cov_path, \"wb\") as f: pickle.dump(scaled_covariates, f)\n",
    "        with open(meta_path, \"wb\") as f: pickle.dump(training_metadata, f)\n",
    "        \n",
    "        artifacts = {\"pipeline\": pipeline_path, \"darts_model\": model_path, \"future_covariates\": cov_path, \"metadata\": meta_path}\n",
    "\n",
    "        # Assinatura\n",
    "        market_cols = [col for col in df_global_support.columns]\n",
    "        full_input_dict = {\n",
    "            **{col: [0.0] for col in market_cols},\n",
    "            \"data\": [\"2025-01-01\"], \"codigo_loja\": [\"1\"], \"target_vendas\": [1000.0],\n",
    "            \"n\": [35], \"is_feriado\": [0.0], \"cluster_loja\": [\"A\"], \"sigla_uf\": [\"SP\"], \"tipo_loja\": [\"SHOPPING\"], \"modelo_loja\": [\"PADRAO\"]\n",
    "        }\n",
    "        input_example = pd.DataFrame(full_input_dict)\n",
    "        output_example = pd.DataFrame({\"data_previsao\": [\"2025-01-02\"], \"previsao_venda\": [1050.0], \"codigo_loja\": [\"1\"]})\n",
    "        signature = infer_signature(input_example, output_example)\n",
    "\n",
    "        # Log do Modelo\n",
    "        model_info = mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"model\",\n",
    "            python_model=UnifiedForecaster(), \n",
    "            artifacts=artifacts,\n",
    "            input_example=input_example,\n",
    "            signature=signature,\n",
    "            metadata={\"description\": \"lightgbm_retrain_checked\"}, \n",
    "            registered_model_name=catalog_model_name\n",
    "        )\n",
    "        \n",
    "        # Promo√ß√£o @Champion\n",
    "        client = MlflowClient()\n",
    "        mv = model_info.registered_model_version\n",
    "        client.set_registered_model_alias(name=catalog_model_name, alias=\"Champion\", version=mv)\n",
    "        \n",
    "        client.update_model_version(\n",
    "            name=catalog_model_name, version=mv,\n",
    "            description=f\"Auto-Retrain. RMSE Check: {rmse_check:.2f}. Pipeline ID: {parent_run.info.run_id}\"\n",
    "        )\n",
    "\n",
    "        for p in [pipeline_path, model_path, cov_path, meta_path]:\n",
    "            if os.path.exists(p): os.remove(p)\n",
    "\n",
    "print(f\"\\n‚ú® Pipeline Finalizado com Sucesso! RMSE Validado: {rmse_check:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cvc_treino_validacao_final_deploy",
   "widgets": {
    "catalog": {
     "currentValue": "ds_dev",
     "nuid": "a5afd31d-9d96-4b27-8242-80bde0ca1de9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ds_dev",
      "label": "4. Cat√°logo",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ds_dev",
      "label": "4. Cat√°logo",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_treino": {
     "currentValue": "2025-01-01",
     "nuid": "b95f539d-8763-4de6-9099-5bbdb42af154",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_validacao": {
     "currentValue": "2025-12-31",
     "nuid": "3336f606-255f-43b8-802c-5c653e4615bd",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida√ß√£o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida√ß√£o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_inicio_treino": {
     "currentValue": "2025-10-01",
     "nuid": "2881cf51-956c-4c47-b54d-2b31d7b66310",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2019-01-01",
      "label": "1. In√≠cio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2019-01-01",
      "label": "1. In√≠cio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "forecast_horizon": {
     "currentValue": "35",
     "nuid": "42d8a644-fc09-4204-ab4f-997f1688de99",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "lags": {
     "currentValue": "5",
     "nuid": "ef2c25cf-9bb7-46d2-8e50-4d63be887f95",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "n_epochs": {
     "currentValue": "20",
     "nuid": "512974af-0ec2-4416-bddd-efe8d195db3f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "20",
      "label": "6. √âpocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "20",
      "label": "6. √âpocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
