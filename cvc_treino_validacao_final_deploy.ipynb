{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c5e7727-af0f-4472-8606-2d4b2d689f02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 0. IMPORTS E SETUP ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Adiciona o diret√≥rio raiz ao path para importar os m√≥dulos 'src'\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Imports dos M√≥dulos do Projeto\n",
    "from src.validation.config import Config\n",
    "from src.validation.data import DataIngestion\n",
    "from src.validation.pipeline import ProjectPipeline\n",
    "from src.validation.trainer import ModelTrainer \n",
    "from src.deploy.wrapper import UnifiedForecaster\n",
    "\n",
    "# Bibliotecas de Modelagem e MLflow\n",
    "from darts.models import LightGBMModel\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Configura√ß√µes de Otimiza√ß√£o do Spark (Delta Lake)\n",
    "spark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.databricks.delta.autoCompact.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f187f3d1-aab3-4e90-b99a-d3c18d487f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. CONFIGURA√á√ÉO DO AMBIENTE E DATAS\n",
    "# ==============================================================================\n",
    "config = Config(spark)\n",
    "\n",
    "# [IMPORTANTE] For√ßa o nome do experimento para ser o de DEPLOY\n",
    "config.EXPERIMENT_NAME = \"/Workspace/Shared/data_science/projetos/cvc_curva_de_vendas_por_canal/experiments/Model_Deploy_CVC_Loja\"\n",
    "\n",
    "# --- CORRE√á√ÉO AQUI ---\n",
    "# Recuamos 2 meses para garantir que o horizonte de 35 dias esteja coberto pelos dados atuais (que param em 20/01)\n",
    "data_final_deploy = pd.to_datetime(datetime.today().strftime(\"%Y-%m-01\")) - relativedelta(months=2)\n",
    "\n",
    "data_inicio_validacao = data_final_deploy - relativedelta(months=2)\n",
    "\n",
    "config.TRAIN_END_DATE = data_final_deploy.strftime(\"%Y-%m-%d\")\n",
    "config.VAL_START_DATE = data_inicio_validacao.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# A ingest√£o continua pegando tudo o que tem dispon√≠vel\n",
    "data_limite_ingestao = pd.to_datetime(datetime.today()) + relativedelta(days=90)\n",
    "config.INGESTION_END = data_limite_ingestao.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"üìÇ EXPERIMENTO ALVO: {config.EXPERIMENT_NAME}\")\n",
    "print(f\"‚è±Ô∏è PER√çODO DE TREINO: {config.DATA_START} at√© {config.TRAIN_END_DATE}\")\n",
    "print(f\"üì• PER√çODO DE INGEST√ÉO (Covari√°veis): At√© {config.INGESTION_END}\")\n",
    "print(f\"üîç JANELA DE TESTE (BACKTEST): {config.VAL_START_DATE} at√© {config.TRAIN_END_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f9ae8cb-fc7a-4871-bc79-eb59cd92102a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(config.DATA_START)\n",
    "print(config.VAL_START_DATE)\n",
    "print(config.TRAIN_END_DATE)\n",
    "print(config.INGESTION_END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90d7e116-d298-4cf4-8921-ef53820633b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# 3. INGEST√ÉO E PREPARA√á√ÉO (VERS√ÉO LIMPA)\n",
    "# ==========================================================================\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- 1. Ingest√£o e Filtros ---\n",
    "ingestion = DataIngestion(spark, config)\n",
    "df_spark_raw = ingestion.create_training_set()\n",
    "\n",
    "# Filtra janela de interesse (Hist√≥rico + Futuro para Covari√°veis)\n",
    "df_spark_filtered = df_spark_raw.filter(\n",
    "    (df_spark_raw.data >= config.DATA_START) & (df_spark_raw.data <= config.INGESTION_END)\n",
    ")\n",
    "df_global_support = ingestion.get_global_support()[config.DATA_START : config.INGESTION_END]\n",
    "\n",
    "print(\"‚è≥ Construindo objetos Darts...\")\n",
    "# Gera as listas iniciais (Covari√°veis assumidas como completas vindo da ingest√£o)\n",
    "full_target_list_long, full_covariates_list = ingestion.build_darts_objects(df_spark_filtered, df_global_support)\n",
    "\n",
    "# --- 2. Tratamento do Target (Corte Seguro) ---\n",
    "# Removemos apenas o futuro do target (vendas), mantendo o hist√≥rico at√© hoje.\n",
    "# A l√≥gica 'if/else' evita erros se a loja parou de vender antes de hoje.\n",
    "cut_date = pd.Timestamp(datetime.today().date())\n",
    "full_target_list = []\n",
    "\n",
    "for ts in full_target_list_long:\n",
    "    if ts.end_time() > cut_date:\n",
    "        full_target_list.append(ts.drop_after(cut_date))\n",
    "    else:\n",
    "        full_target_list.append(ts)\n",
    "\n",
    "# Debug Final\n",
    "print(f\"‚úÖ Processamento Conclu√≠do.\")\n",
    "if full_target_list:\n",
    "    print(f\"üîç [DEBUG] Target (amostra) termina em: {full_target_list[0].end_time()}\")\n",
    "if full_covariates_list:\n",
    "    print(f\"üîç [DEBUG] Covariates (amostra) terminam em: {full_covariates_list[0].end_time()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbed633e-f394-4cfd-bc32-2f3103c0fc99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. IN√çCIO DA EXECU√á√ÉO MESTRA\n",
    "# ==============================================================================\n",
    "mlflow.set_experiment(config.EXPERIMENT_NAME)\n",
    "with mlflow.start_run(run_name=f\"Pipeline_Completo_{config.VERSION}\") as parent_run:\n",
    "    \n",
    "    print(f\"üîó Parent Run ID: {parent_run.info.run_id}\")\n",
    "    mlflow.log_param(\"pipeline_type\", \"auto_retrain_w_quality_gate\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 4. PREPARA√á√ÉO DO PIPELINE (SCALERS)\n",
    "    # ==========================================================================\n",
    "    pipeline = ProjectPipeline()\n",
    "    val_cutoff_dt = pd.Timestamp(config.VAL_START_DATE) - pd.Timedelta(days=1)\n",
    "\n",
    "    # Fit nos dados hist√≥ricos (evita Data Leakage)\n",
    "    train_subset_for_fit = [s.drop_after(val_cutoff_dt) for s in full_target_list]\n",
    "    cov_subset_for_fit = [c.drop_after(val_cutoff_dt) for c in full_covariates_list]\n",
    "\n",
    "    print(\"‚öôÔ∏è Ajustando Scalers...\")\n",
    "    pipeline.fit(train_subset_for_fit, cov_subset_for_fit)\n",
    "\n",
    "    # Transforma base completa\n",
    "    scaled_series, scaled_covariates = pipeline.transform(full_target_list, full_covariates_list)\n",
    "    \n",
    "    train_series_static = [s.drop_after(val_cutoff_dt) for s in scaled_series]\n",
    "    train_cov_static = [c.drop_after(val_cutoff_dt) for c in scaled_covariates]\n",
    "    val_series_original = pipeline.inverse_transform(scaled_series, partial=True)\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 5. VALIDA√á√ÉO AUTOM√ÅTICA (BACKTEST)\n",
    "    # ==========================================================================\n",
    "    model_params = {\n",
    "        \"lags\": 12,\n",
    "        \"lags_future_covariates\": [0,1,2,3],\n",
    "        \"output_chunk_length\": 1,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    models_dict = {\"model_deploy\": LightGBMModel(**model_params)}\n",
    "\n",
    "    print(f\"\\nüöÄ Executando Backtest (3 Meses)...\")\n",
    "    trainer = ModelTrainer(config, models_dict)\n",
    "    trainer.train_evaluate_walkforward(\n",
    "        train_series_static=train_series_static,\n",
    "        train_covs_static=train_cov_static,\n",
    "        full_series_scaled=scaled_series,\n",
    "        full_covariates_scaled=scaled_covariates,\n",
    "        val_series_original=val_series_original,\n",
    "        target_pipeline=pipeline\n",
    "    )\n",
    "    \n",
    "    # ==========================================================================\n",
    "    # 6. GATEKEEPER (TRAVA DE SEGURAN√áA)\n",
    "    # ==========================================================================\n",
    "    print(\"\\nüëÆ Verificando Qualidade do Modelo (Gatekeeper)...\")\n",
    "    \n",
    "    # A. L√™ os resultados salvos na tabela Delta pela valida√ß√£o acima\n",
    "    # Filtra apenas pela vers√£o atual do pipeline para n√£o pegar lixo antigo\n",
    "    df_results = spark.table(\"ds_dev.cvc_val.resultado_metricas_treinamento_lojas\") \\\n",
    "                      .filter(F.col(\"versao\") == config.VERSION)\n",
    "    \n",
    "    # B. Descobre qual foi o √∫ltimo m√™s validado (o m√™s mais recente)\n",
    "    try:\n",
    "        last_month_str = df_results.select(F.max(\"metrica_mes\")).collect()[0][0]\n",
    "    except:\n",
    "        raise Exception(\"‚ùå ERRO CR√çTICO: Tabela de resultados vazia. Valida√ß√£o falhou silenciosamente?\")\n",
    "\n",
    "    if not last_month_str:\n",
    "        # Fallback se n√£o encontrar m√™s (pode acontecer se o backtest pular todos os meses)\n",
    "        print(\"‚ö†Ô∏è Aviso: N√£o foi poss√≠vel identificar m√™s de valida√ß√£o. Tentando pegar o √∫ltimo dispon√≠vel.\")\n",
    "        last_month_str = config.TRAIN_END_DATE[:7] # YYYY-MM\n",
    "\n",
    "    print(f\"   üìÖ Analisando m√™s de corte: {last_month_str}\")\n",
    "\n",
    "    # C. Calcula o RMSE especificamente para este m√™s\n",
    "    rmse_check = df_results.filter(F.col(\"metrica_mes\") == last_month_str) \\\n",
    "                           .select(F.sqrt(F.mean(F.pow(F.col(\"real\") - F.col(\"previsao\"), 2))).alias(\"rmse\")) \\\n",
    "                           .collect()[0][\"rmse\"]\n",
    "\n",
    "    # Se der Nulo (sem dados), assume erro\n",
    "    if rmse_check is None: rmse_check = 999999.0\n",
    "    \n",
    "    print(f\"   üìâ RMSE Calculado: {rmse_check:.4f}\")\n",
    "    \n",
    "    # Loga na Run Pai para auditoria\n",
    "    mlflow.log_metric(\"gatekeeper_last_month_rmse\", rmse_check)\n",
    "\n",
    "    # D. APLICA A TRAVA\n",
    "    LIMIT_RMSE = 1000000\n",
    "    \n",
    "    if rmse_check >= LIMIT_RMSE:\n",
    "        error_msg = (f\"‚õî BLOQUEIO DE DEPLOY: RMSE do √∫ltimo m√™s ({rmse_check:.2f}) \"\n",
    "                     f\"excedeu o limite aceit√°vel ({LIMIT_RMSE}). Pipeline Abortado.\")\n",
    "        # Marca a run pai como FALHA explicitamente\n",
    "        mlflow.set_tag(\"pipeline_status\", \"BLOCKED_BY_QUALITY\")\n",
    "        raise Exception(error_msg)\n",
    "    \n",
    "    print(\"‚úÖ Crit√©rio de Qualidade Aprovado! Prosseguindo para Deploy.\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 7. TREINAMENTO FINAL (FULL DATASET)\n",
    "    # ==========================================================================\n",
    "    print(\"\\nüèãÔ∏è Iniciando Treinamento Final (Full Dataset)...\")\n",
    "    final_model = LightGBMModel(**model_params)\n",
    "    final_model.fit(scaled_series, future_covariates=scaled_covariates)\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 8. REGISTRO E DEPLOY\n",
    "    # ==========================================================================\n",
    "\n",
    "    catalog_model_name = f\"{config.CATALOG}.cvc_pred.cvc_lojas_forecast_production\"\n",
    "    \n",
    "    print(f\"üíæ Registrando modelo: {catalog_model_name}\")\n",
    "    \n",
    "    # Tags de rastreabilidade\n",
    "    mlflow.set_tag(\"parent_run_id\", parent_run.info.run_id)\n",
    "    mlflow.set_tag(\"quality_check_rmse\", f\"{rmse_check:.2f}\")\n",
    "\n",
    "    # Prepara√ß√£o de Artefatos (Pipeline, Modelo, Metadados)\n",
    "    sample_ts = full_target_list[0]\n",
    "    sample_cov = full_covariates_list[0]\n",
    "    \n",
    "    training_metadata = {\n",
    "        \"static_cols_order\": [c for c in sample_ts.static_covariates.columns.tolist() if c != \"codigo_loja\"],\n",
    "        \"covariate_cols_order\": sample_cov.components.tolist(),\n",
    "        \"max_lag\": 15\n",
    "    }\n",
    "\n",
    "    pipeline_path, model_path, cov_path, meta_path = \"pipeline.pkl\", \"lgbm_model.pkl\", \"future_covariates.pkl\", \"model_metadata.pkl\"\n",
    "    \n",
    "    with open(pipeline_path, \"wb\") as f: pickle.dump(pipeline, f)\n",
    "    with open(model_path, \"wb\") as f: pickle.dump(final_model, f)\n",
    "    with open(cov_path, \"wb\") as f: pickle.dump(scaled_covariates, f)\n",
    "    with open(meta_path, \"wb\") as f: pickle.dump(training_metadata, f)\n",
    "    \n",
    "    artifacts = {\"pipeline\": pipeline_path, \"darts_model\": model_path, \"future_covariates\": cov_path, \"metadata\": meta_path}\n",
    "\n",
    "    # Assinatura\n",
    "    market_cols = [col for col in df_global_support.columns]\n",
    "    full_input_dict = {\n",
    "        **{col: [0.0] for col in market_cols},\n",
    "        \"data\": [\"2025-01-01\"], \"codigo_loja\": [\"1\"], \"target_vendas\": [1000.0],\n",
    "        \"n\": [35], \"is_feriado\": [0.0], \"cluster_loja\": [\"A\"], \"sigla_uf\": [\"SP\"], \"tipo_loja\": [\"SHOPPING\"], \"modelo_loja\": [\"PADRAO\"]\n",
    "    }\n",
    "    input_example = pd.DataFrame(full_input_dict)\n",
    "    output_example = pd.DataFrame({\"data_previsao\": [\"2025-01-02\"], \"previsao_venda\": [1050.0], \"codigo_loja\": [\"1\"]})\n",
    "    signature = infer_signature(input_example, output_example)\n",
    "\n",
    "    # Log do Modelo\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=UnifiedForecaster(), \n",
    "        artifacts=artifacts,\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        metadata={\"description\": \"lightgbm\"}, \n",
    "        registered_model_name=catalog_model_name\n",
    "    )\n",
    "    \n",
    "    # Promo√ß√£o @Champion\n",
    "    client = MlflowClient()\n",
    "    mv = model_info.registered_model_version\n",
    "    client.set_registered_model_alias(name=catalog_model_name, alias=\"Champion\", version=mv)\n",
    "    \n",
    "    client.update_model_version(\n",
    "        name=catalog_model_name, version=mv,\n",
    "        description=f\"Auto-Retrain. RMSE Check: {rmse_check:.2f}. Pipeline ID: {parent_run.info.run_id}\"\n",
    "    )\n",
    "\n",
    "    for p in [pipeline_path, model_path, cov_path, meta_path]:\n",
    "        if os.path.exists(p): os.remove(p)\n",
    "\n",
    "print(f\"\\n‚ú® Pipeline Finalizado com Sucesso! RMSE Validado: {rmse_check:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cvc_treino_validacao_final_deploy",
   "widgets": {
    "catalog": {
     "currentValue": "ds_dev",
     "nuid": "a5afd31d-9d96-4b27-8242-80bde0ca1de9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ds_dev",
      "label": "4. Cat√°logo",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ds_dev",
      "label": "4. Cat√°logo",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_treino": {
     "currentValue": "",
     "nuid": "b95f539d-8763-4de6-9099-5bbdb42af154",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_validacao": {
     "currentValue": "",
     "nuid": "3336f606-255f-43b8-802c-5c653e4615bd",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida√ß√£o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida√ß√£o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_inicio_treino": {
     "currentValue": "2019-01-01",
     "nuid": "2881cf51-956c-4c47-b54d-2b31d7b66310",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2019-01-01",
      "label": "1. In√≠cio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2019-01-01",
      "label": "1. In√≠cio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "forecast_horizon": {
     "currentValue": "35",
     "nuid": "42d8a644-fc09-4204-ab4f-997f1688de99",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "lags": {
     "currentValue": "5",
     "nuid": "ef2c25cf-9bb7-46d2-8e50-4d63be887f95",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "n_epochs": {
     "currentValue": "20",
     "nuid": "512974af-0ec2-4416-bddd-efe8d195db3f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "20",
      "label": "6. √âpocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "20",
      "label": "6. √âpocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
