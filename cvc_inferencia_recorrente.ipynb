{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff287ba8-3984-43a3-84f5-180cf0709723",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üîÑ Infer√™ncia Recorrente de Vendas - CVC Lojas\n",
    "\n",
    "## üéØ Objetivo\n",
    "Execu√ß√£o peri√≥dica (Semanal/Mensal) para gerar novas previs√µes de vendas.\n",
    "Este notebook n√£o treina modelos. Ele carrega o modelo produtivo (`All-in-One`) e gera forecast baseando-se no hist√≥rico mais recente.\n",
    "\n",
    "## ‚öôÔ∏è Fluxo de Execu√ß√£o\n",
    "1.  **Context Loading:** Carrega os √∫ltimos 90 dias de vendas (Janela de Contexto) do Data Lake.\n",
    "2.  **Model Loading:** Baixa o modelo do Unity Catalog (`Usage: Production`).\n",
    "3.  **Inference:** O Wrapper `UnifiedForecaster` recebe o contexto, normaliza, prev√™ e desnormaliza.\n",
    "4.  **Persistence:** Salva os resultados na tabela `bip_vprevisao_lojas_futuro`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d14b5890-6b94-43bb-b975-a3792429d02a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- SETUP INICIAL ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from src.validation.config import Config\n",
    "from src.validation.data import DataIngestion\n",
    "from datetime import timedelta, date\n",
    "import mlflow\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Darts classes para Wrapper funcionar\n",
    "from darts import TimeSeries\n",
    "\n",
    "# Configs Spark\n",
    "spark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.databricks.delta.autoCompact.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4922c5a6-a6c4-4c2c-899b-58698ae43935",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 1. DEFINI√á√ÉO DA JANELA DE CONTEXTO ---\n",
    "\n",
    "# Simulando \"Hoje\" (em prod usar date.today())\n",
    "#today = date.today()\n",
    "today = datetime.strptime(\"2025-02-01\", \"%Y-%m-%d\").date() \n",
    "\n",
    "# Janela de Lookback: precisamos de hist√≥rico suficiente para os Lags do modelo (ex: 60-90 dias)\n",
    "context_days = 90 \n",
    "start_context = today - timedelta(days=context_days)\n",
    "\n",
    "# Config Din√¢mica\n",
    "config = Config(spark)\n",
    "config.DATA_START = start_context.strftime(\"%Y-%m-%d\")\n",
    "config.INGESTION_END = today.strftime(\"%Y-%m-%d\")\n",
    "config.SCHEMA = \"cvc_pred\"\n",
    "\n",
    "print(f\"üìÖ Data de Refer√™ncia (Hoje): {today}\")\n",
    "print(f\"üîé Carregando contexto a partir de: {config.DATA_START}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa8f1a9a-ddeb-4ef2-ad92-c5b3dd0735ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 2. CARREGAMENTO DO CONTEXTO (SPARK) ---\n",
    "# Reutilizamos a classe DataIngestion para garantir consist√™ncia nas features\n",
    "ingestion = DataIngestion(spark, config)\n",
    "\n",
    "print(\"   ‚è≥ Lendo dados hist√≥ricos recentes...\")\n",
    "df_context_spark = ingestion.create_training_set()\n",
    "\n",
    "# Filtro de Seguran√ßa e Sele√ß√£o de Colunas\n",
    "df_context_spark = df_context_spark.filter(\n",
    "    F.col(\"DATA\").between(config.DATA_START, config.INGESTION_END)\n",
    ")\n",
    "\n",
    "# Traz para Pandas (Driver) - Volume pequeno pois √© s√≥ janela recente\n",
    "df_context_pd = df_context_spark.toPandas()\n",
    "df_context_pd['DATA'] = pd.to_datetime(df_context_pd['DATA'])\n",
    "\n",
    "# Injeta parametro 'n' para o wrapper saber o horizonte desejado\n",
    "FORECAST_HORIZON = 35\n",
    "df_context_pd['n'] = FORECAST_HORIZON\n",
    "\n",
    "print(f\"   ‚úÖ Contexto Carregado: {len(df_context_pd)} registros de vendas recentes.\")\n",
    "display(df_context_pd.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a35f23fc-6484-4b96-b048-03f40ef90a20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 3. CARREGAMENTO DO MODELO ---\n",
    "\n",
    "model_name = f\"{config.CATALOG}.{config.SCHEMA}.cvc_lojas_forecast_production\"\n",
    "print(f\"üì• Baixando modelo do Unity Catalog: {model_name}...\")\n",
    "\n",
    "# Em produ√ß√£o real, voc√™ usaria um Alias como \"@Prod\" ou a vers√£o specifica\n",
    "# modelo = mlflow.pyfunc.load_model(f\"models:/{model_name}@Prod\")\n",
    "# Aqui carregamos a √∫ltima vers√£o logs\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"models:/{model_name}/15\")\n",
    "print(\"   ‚úÖ Modelo Carregado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "832f7d90-9880-4b38-b920-1cf90a13d4af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- PREPARA√á√ÉO DE DADOS DE MERCADO ---\n",
    "\n",
    "# 1. Carrega a tabela de suporte (a mesma usada no treino)\n",
    "df_market_spark = spark.table(f\"{config.CATALOG}.{config.SCHEMA}.bip_vhistorico_suporte_canal_loja\")\n",
    "\n",
    "# 2. Pivota para criar as colunas (IPCA, DOLAR...)\n",
    "# Importante: O nome das colunas deve bater exatamente com o treino\n",
    "df_market_wide = (df_market_spark\n",
    "    .groupBy(\"DATA\")\n",
    "    .pivot(\"METRICAS\")\n",
    "    .agg(F.sum(\"VALOR\"))\n",
    "    .na.fill(0.0)\n",
    ")\n",
    "\n",
    "# 3. Converte para Pandas para fazer o merge local (j√° que a infer√™ncia √© pandas)\n",
    "pdf_market = df_market_wide.toPandas()\n",
    "pdf_market['DATA'] = pd.to_datetime(pdf_market['DATA']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"üìä M√©tricas de mercado carregadas: {pdf_market.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b059bc0b-85c2-46a8-8ea6-27220dd027c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- MONTAGEM FINAL DO CONTEXTO (MERCADO + FUTURO) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. PREPARA√á√ÉO DE DADOS DE MERCADO (Incorporado)\n",
    "# ==============================================================================\n",
    "print(\"üìä Carregando dados de mercado (IPCA, D√≥lar, Feriados)...\")\n",
    "\n",
    "# Carrega a tabela de suporte\n",
    "df_market_spark = spark.table(f\"{config.CATALOG}.{config.SCHEMA}.bip_vhistorico_suporte_canal_loja\")\n",
    "\n",
    "# Pivota para formato Wide (Colunas: IPCA, DOLAR...)\n",
    "df_market_wide = (df_market_spark\n",
    "    .groupBy(\"DATA\")\n",
    "    .pivot(\"METRICAS\")\n",
    "    .agg(F.sum(\"VALOR\"))\n",
    "    .na.fill(0.0)\n",
    ")\n",
    "\n",
    "# Traz para Pandas\n",
    "pdf_market = df_market_wide.toPandas()\n",
    "# Garante string YYYY-MM-DD para join seguro\n",
    "pdf_market['DATA'] = pd.to_datetime(pdf_market['DATA']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. CRIA√á√ÉO DO ESQUELETO FUTURO E MERGE\n",
    "# ==============================================================================\n",
    "print(\"‚è≥ Montando esqueleto de datas futuras para previs√£o...\")\n",
    "\n",
    "# Garante datetime no contexto original\n",
    "df_context_pd['DATA'] = pd.to_datetime(df_context_pd['DATA'])\n",
    "last_date = df_context_pd['DATA'].max()\n",
    "\n",
    "# Gera datas futuras (+15 dias de buffer para seguran√ßa dos lags)\n",
    "future_horizon_days = FORECAST_HORIZON + 15\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=future_horizon_days, freq='D')\n",
    "\n",
    "# Identifica colunas est√°ticas para replicar (UF, Cluster, etc.)\n",
    "static_cols = ['CODIGO_LOJA', 'CLUSTER_LOJA', 'SIGLA_UF', 'TIPO_LOJA', 'MODELO_LOJA']\n",
    "static_cols = [c for c in static_cols if c in df_context_pd.columns]\n",
    "\n",
    "# Pega a √∫ltima \"foto\" de cada loja\n",
    "df_stores_reference = df_context_pd.sort_values('DATA').groupby('CODIGO_LOJA')[static_cols].tail(1)\n",
    "\n",
    "# Cross Join: Todas as Lojas x Todas as Datas Futuras\n",
    "df_future_skeleton = df_stores_reference.assign(key=1).merge(\n",
    "    pd.DataFrame({'DATA': future_dates, 'key': 1}), \n",
    "    on='key'\n",
    ").drop('key', axis=1)\n",
    "\n",
    "# Sinaliza que √© futuro (Target NaN) e define horizonte\n",
    "df_future_skeleton['TARGET_VENDAS'] = np.nan\n",
    "df_future_skeleton['n'] = FORECAST_HORIZON\n",
    "\n",
    "# Une Hist√≥rico + Futuro\n",
    "df_full_timeline = pd.concat([df_context_pd, df_future_skeleton], ignore_index=True)\n",
    "df_full_timeline['DATA'] = df_full_timeline['DATA'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# MERGE FINAL: Aplica os dados de mercado nas datas futuras\n",
    "df_inference_final = pd.merge(\n",
    "    df_full_timeline, \n",
    "    pdf_market, \n",
    "    on='DATA', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Preenche buracos eventuais no mercado com 0.0\n",
    "cols_mercado = [c for c in pdf_market.columns if c != 'DATA']\n",
    "df_inference_final[cols_mercado] = df_inference_final[cols_mercado].fillna(0.0)\n",
    "\n",
    "# Ajuste de tipos\n",
    "df_inference_final['CODIGO_LOJA'] = df_inference_final['CODIGO_LOJA'].astype(str)\n",
    "\n",
    "print(f\"‚úÖ Contexto completo pronto! (Hist√≥rico + Futuro com Mercado)\")\n",
    "print(f\"   Total de linhas: {len(df_inference_final)}\")\n",
    "display(df_inference_final.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d7cf4c1-beb8-4a03-86f2-019fbd283356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- PREVIS√ÉO ---\n",
    "print(\"üîÆ Gerando previs√µes...\")\n",
    "\n",
    "# O modelo vai:\n",
    "# 1. Receber IPCA, DOLAR, FERIADO, VENDAS...\n",
    "# 2. O Wrapper vai separar: VENDAS -> Passado; RESTO -> Futuro\n",
    "df_inference_final = df_inference_final.loc[:, ~df_inference_final.columns.duplicated()]\n",
    "\n",
    "print(\"‚úÖ Colunas duplicadas removidas antes da chamada do modelo.\")\n",
    "\n",
    "# 2. Agora chama a previs√£o\n",
    "forecast_df = loaded_model.predict(df_inference_final)\n",
    "display(forecast_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b56cf72d-2dc4-4f8c-8ace-6d9505578e82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#   # --- 5. PERSIST√äNCIA (WRITE BACK) ---\n",
    "#   output_table = f\"{config.CATALOG}.{config.SCHEMA}.bip_vprevisao_lojas_futuro\"\n",
    "#   \n",
    "#   print(f\"üíæ Salvando resultados em: {output_table}\")\n",
    "#   \n",
    "#   try:\n",
    "#       (spark.createDataFrame(forecast_df)\n",
    "#        .write\n",
    "#        .format(\"delta\")\n",
    "#        .mode(\"append\") # Append hist√≥rico de previs√µes\n",
    "#        .option(\"mergeSchema\", \"true\")\n",
    "#        .saveAsTable(output_table)\n",
    "#       )\n",
    "#       \n",
    "#       spark.sql(f\"OPTIMIZE {output_table}\")\n",
    "#       print(\"   ‚ú® Sucesso! Dados salvos e otimizados.\")\n",
    "#   except Exception as e:\n",
    "#       print(f\"‚ùå Erro ao salvar: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cvc_inferencia_recorrente",
   "widgets": {
    "catalog": {
     "currentValue": "ds_dev",
     "nuid": "4baaa425-c6d7-4b26-8cbe-ca720f35b0af",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ds_dev",
      "label": "4. Cat√°logo",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ds_dev",
      "label": "4. Cat√°logo",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_treino": {
     "currentValue": "2025-01-01",
     "nuid": "c45fc489-8454-433c-b6cd-13a1372a8ab0",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_validacao": {
     "currentValue": "2025-12-31",
     "nuid": "791a2ba0-ac35-4e45-aca8-90acfe1a63d7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida√ß√£o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida√ß√£o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_inicio_treino": {
     "currentValue": "2019-01-01",
     "nuid": "a8f75fff-84ae-49e1-97f5-2bf352aa6d1d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2019-01-01",
      "label": "1. In√≠cio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2019-01-01",
      "label": "1. In√≠cio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "forecast_horizon": {
     "currentValue": "35",
     "nuid": "4b2598a8-328e-41df-9cc4-a1de1b865d04",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "lags": {
     "currentValue": "5",
     "nuid": "abe2b8ad-b780-4df7-8718-16bba7c59f03",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "n_epochs": {
     "currentValue": "20",
     "nuid": "1487beaf-13b7-4b3a-8fea-729ab40c6e45",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "20",
      "label": "6. √âpocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "20",
      "label": "6. √âpocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
