{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff287ba8-3984-43a3-84f5-180cf0709723",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üîÑ Infer√™ncia Recorrente (Batch Scoring)\n",
    "\n",
    "## üéØ Objetivo\n",
    "Gerar previs√µes para os pr√≥ximos dias (Forecast Horizon) usando o modelo produtivo.\n",
    "\n",
    "## ‚öôÔ∏è Fluxo\n",
    "1.  **Carrega Contexto**: L√™ os √∫ltimos 90 dias.\n",
    "2.  **Carrega Modelo**: Baixa a vers√£o `Champion`.\n",
    "3.  **Previs√£o**: Gera e persiste as previs√µes.\n",
    "\n",
    "---\n",
    "\n",
    "# üîÑ Infer√™ncia Recorrente de Vendas - CVC Lojas\n",
    "\n",
    "## üéØ Objetivo\n",
    "Execu√ß√£o peri√≥dica (Semanal/Mensal) para gerar novas previs√µes de vendas.\n",
    "Este notebook n√£o treina modelos. Ele carrega o modelo produtivo (`All-in-One`) e gera forecast baseando-se no hist√≥rico mais recente.\n",
    "\n",
    "## ‚öôÔ∏è Fluxo de Execu√ß√£o\n",
    "1.  **Context Loading:** Carrega os √∫ltimos 90 dias de vendas (Janela de Contexto) do Data Lake.\n",
    "2.  **Model Loading:** Baixa o modelo do Unity Catalog (`Usage: Production`).\n",
    "3.  **Inference:** O Wrapper `UnifiedForecaster` recebe o contexto, normaliza, prev√™ e desnormaliza.\n",
    "4.  **Persistence:** Salva os resultados na tabela `bip_vprevisao_lojas_futuro`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d14b5890-6b94-43bb-b975-a3792429d02a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importa√ß√£o de bibliotecas essenciais\n",
    "# --- SETUP INICIAL ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from src.validation.config import Config\n",
    "from src.validation.data import DataIngestion\n",
    "from datetime import timedelta, date\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Darts classes para Wrapper funcionar\n",
    "from darts import TimeSeries\n",
    "\n",
    "# Configs Spark\n",
    "spark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.databricks.delta.autoCompact.enabled\", \"true\")\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4922c5a6-a6c4-4c2c-899b-58698ae43935",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 1. DEFINI√á√ÉO DA JANELA DE CONTEXTO ---\n",
    "# Simulando \"Hoje\" (em prod usar date.today())\n",
    "today = date.today()\n",
    "#today = datetime.strptime(\"2025-02-01\", \"%Y-%m-%d\").date() \n",
    "\n",
    "# Janela de Lookback: precisamos de hist√≥rico suficiente para os Lags do modelo (ex: 60-90 dias)\n",
    "context_days = 90 \n",
    "start_context = today - timedelta(days=context_days)\n",
    "\n",
    "# Config Din√¢mica\n",
    "config = Config(spark)\n",
    "config.DATA_START = start_context.strftime(\"%Y-%m-%d\")\n",
    "config.INGESTION_END = today.strftime(\"%Y-%m-%d\")\n",
    "config.SCHEMA = \"cvc_pred\"\n",
    "\n",
    "print(f\"üìÖ Data de Refer√™ncia (Hoje): {today}\")\n",
    "print(f\"üîé Carregando contexto a partir de: {config.DATA_START}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa8f1a9a-ddeb-4ef2-ad92-c5b3dd0735ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 2. CARREGAMENTO DO CONTEXTO (SPARK) ---\n",
    "# Reutilizamos a classe DataIngestion para garantir consist√™ncia nas features\n",
    "ingestion = DataIngestion(spark, config)\n",
    "\n",
    "print(\"   ‚è≥ Lendo dados hist√≥ricos recentes...\")\n",
    "df_context_spark = ingestion.create_training_set()\n",
    "\n",
    "# Filtro de Seguran√ßa e Sele√ß√£o de Colunas\n",
    "df_context_spark = df_context_spark.filter(\n",
    "    F.col(\"DATA\").between(config.DATA_START, config.INGESTION_END)\n",
    ")\n",
    "\n",
    "# Traz para Pandas (Driver) - Volume pequeno pois √© s√≥ janela recente\n",
    "df_context_pd = df_context_spark.toPandas()\n",
    "df_context_pd['data'] = pd.to_datetime(df_context_pd['data'])\n",
    "\n",
    "# Injeta parametro 'n' para o wrapper saber o horizonte desejado\n",
    "FORECAST_HORIZON = 35\n",
    "df_context_pd['n'] = FORECAST_HORIZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a35f23fc-6484-4b96-b048-03f40ef90a20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Carrega o modelo validado do registro\n",
    "# --- 3. CARREGAMENTO DO MODELO ---\n",
    "model_name = f\"{config.CATALOG}.{config.SCHEMA}.cvc_lojas_forecast_production\"\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"models:/{model_name}@Champion\")\n",
    "print(\"‚úÖ Modelo Carregado!\")\n",
    "mv = client.get_model_version_by_alias(name=model_name, alias=\"Champion\")\n",
    "\n",
    "print(\"Modelo:\", model_name)\n",
    "print(\"Vers√£o do modelo:\", mv.version)\n",
    "print(\"Run ID:\", mv.run_id)\n",
    "print(\"Current stage:\", mv.current_stage)\n",
    "print(\"Description:\", mv.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "832f7d90-9880-4b38-b920-1cf90a13d4af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- PREPARA√á√ÉO DE DADOS DE MERCADO ---\n",
    "\n",
    "# 1. Carrega a tabela de suporte (a mesma usada no treino)\n",
    "df_market_spark = spark.table(f\"{config.CATALOG}.{config.SCHEMA}.historico_suporte_loja\")\n",
    "\n",
    "# 2. Pivota para criar as colunas (IPCA, DOLAR...)\n",
    "# Importante: O nome das colunas deve bater exatamente com o treino\n",
    "df_market_wide = (df_market_spark\n",
    "    .groupBy(\"data\")\n",
    "    .pivot(\"metricas\")\n",
    "    .agg(F.sum(\"valor\"))\n",
    "    .na.fill(0.0))\n",
    "\n",
    "# 3. Converte para Pandas para fazer o merge local (j√° que a infer√™ncia √© pandas)\n",
    "pdf_market = df_market_wide.toPandas()\n",
    "pdf_market['data'] = pd.to_datetime(pdf_market['data']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b059bc0b-85c2-46a8-8ea6-27220dd027c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- MONTAGEM FINAL DO CONTEXTO (MERCADO + FUTURO) COM AJUSTE DE SCHEMA MLFLOW ---\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. PREPARA√á√ÉO DE DADOS DE MERCADO (Suporte Global)\n",
    "# ==============================================================================\n",
    "print(\"üìä Carregando dados de mercado...\")\n",
    "\n",
    "df_market_spark = spark.table(f\"{config.CATALOG}.{config.SCHEMA}.historico_suporte_loja\")\n",
    "df_market_wide = (df_market_spark\n",
    "    .groupBy(\"data\")\n",
    "    .pivot(\"metricas\")\n",
    "    .agg(F.sum(\"valor\"))\n",
    "    .na.fill(0.0)\n",
    ")\n",
    "\n",
    "pdf_market = df_market_wide.toPandas()\n",
    "pdf_market['data'] = pd.to_datetime(pdf_market['data'])\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. CRIA√á√ÉO DO ESQUELETO EXPANDIDO (¬±3 meses para satisfazer o modelo)\n",
    "# ==============================================================================\n",
    "print(\"‚è≥ Montando timeline completa com margem de seguran√ßa...\")\n",
    "\n",
    "df_context_pd['data'] = pd.to_datetime(df_context_pd['data'])\n",
    "last_date_history = df_context_pd['data'].max()\n",
    "start_date_context = df_context_pd['data'].min()\n",
    "\n",
    "# Margem de 3 meses para tr√°s conforme definido no treinamento (data.py)\n",
    "safe_start_date = start_date_context - pd.DateOffset(months=3)\n",
    "future_dates = pd.date_range(start=last_date_history + pd.Timedelta(days=1), periods=FORECAST_HORIZON + 15, freq='D')\n",
    "\n",
    "# Range total para evitar erros de dimens√£o/quarter\n",
    "inference_range = pd.date_range(start=safe_start_date, end=future_dates.max(), freq='D')\n",
    "\n",
    "static_cols = ['codigo_loja', 'cluster_loja', 'sigla_uf', 'tipo_loja', 'modelo_loja']\n",
    "static_cols = [c for c in static_cols if c in df_context_pd.columns]\n",
    "df_stores_reference = df_context_pd.sort_values('data').groupby('codigo_loja')[static_cols].tail(1)\n",
    "\n",
    "df_full_timeline = df_stores_reference.assign(key=1).merge(\n",
    "    pd.DataFrame({'data': inference_range, 'key': 1}), \n",
    "    on='key'\n",
    ").drop('key', axis=1)\n",
    "\n",
    "# Merge com hist√≥rico DE VENDAS (Target) - Feriado pegaremos da tabela cheia\n",
    "# Primeiro garantimos que os IDs estejam limpos para o merge funcionar\n",
    "df_full_timeline['codigo_loja'] = df_full_timeline['codigo_loja'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "df_context_pd['codigo_loja'] = df_context_pd['codigo_loja'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "df_full_timeline = pd.merge(\n",
    "    df_full_timeline, \n",
    "    df_context_pd[['data', 'codigo_loja', 'target_vendas']], \n",
    "    on=['data', 'codigo_loja'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- CORRE√á√ÉO: Carrega Calend√°rio de Feriados COMPLETO (Passado + Futuro) ---\n",
    "print(\"üóìÔ∏è Carregando calend√°rio oficial de feriados...\")\n",
    "df_feriados_spark = spark.table(f\"{config.CATALOG}.{config.SCHEMA}.historico_feriados_loja\")\n",
    "\n",
    "# Prepara dataframe de feriados\n",
    "df_feriados_pd = (df_feriados_spark\n",
    "    .select(\"codigo_loja\", \"data\", \"valor\")\n",
    "    .withColumn(\"codigo_loja\", F.col(\"codigo_loja\").cast(\"string\"))\n",
    "    .toPandas()\n",
    ")\n",
    "df_feriados_pd['data'] = pd.to_datetime(df_feriados_pd['data'])\n",
    "df_feriados_pd.rename(columns={'valor': 'is_feriado'}, inplace=True)\n",
    "\n",
    "# Garante limpeza do ID de Feriados\n",
    "df_feriados_pd['codigo_loja'] = df_feriados_pd['codigo_loja'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "# Merge de Feriados na Timeline Principal\n",
    "df_full_timeline = pd.merge(\n",
    "    df_full_timeline,\n",
    "    df_feriados_pd,\n",
    "    on=['data', 'codigo_loja'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Preenchimento de nulos\n",
    "df_full_timeline['target_vendas'] = df_full_timeline['target_vendas'].fillna(0.0)\n",
    "df_full_timeline['is_feriado'] = df_full_timeline['is_feriado'].fillna(0.0)\n",
    "df_full_timeline['n'] = int(FORECAST_HORIZON)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. MERGE FINAL E COMPATIBILIZA√á√ÉO DE SCHEMA (MLFLOW)\n",
    "# ==============================================================================\n",
    "\n",
    "df_inference_final = pd.merge(df_full_timeline, pdf_market, on='data', how='left')\n",
    "\n",
    "# Preenchimento de indicadores de mercado (ffill/bfill para garantir a margem de 3 meses)\n",
    "cols_mercado = [c for c in pdf_market.columns if c != 'data']\n",
    "df_inference_final[cols_mercado] = df_inference_final[cols_mercado].ffill().bfill().fillna(0.0)\n",
    "\n",
    "# 1. Limpeza de ID da Loja\n",
    "df_inference_final['codigo_loja'] = (\n",
    "    df_inference_final['codigo_loja']\n",
    "    .astype(str)\n",
    "    .str.replace(r'\\.0$', '', regex=True)\n",
    ")\n",
    "\n",
    "# 2. Tipos Num√©ricos (Garante Double/Float conforme exigido pelo MLflow)\n",
    "for col in cols_mercado + ['target_vendas', 'is_feriado']:\n",
    "    df_inference_final[col] = df_inference_final[col].astype(float)\n",
    "\n",
    "# 3. Ajuste de tipos Long/Integer\n",
    "df_inference_final['n'] = df_inference_final['n'].astype(int)\n",
    "\n",
    "# 4. CONVERS√ÉO DE DATA PARA STRING (Exig√™ncia do Schema do MLflow: 'data': string)\n",
    "# Fazemos isso por √∫ltimo para garantir que o Darts receba o formato correto via Wrapper\n",
    "df_inference_final['data'] = df_inference_final['data'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"‚úÖ Tratamento conclu√≠do. Schema compatibilizado com MLflow.\")\n",
    "print(f\"   Colunas totais: {len(df_inference_final.columns)} | Linhas: {len(df_inference_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d7cf4c1-beb8-4a03-86f2-019fbd283356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Executa a infer√™ncia (Forecast)\n",
    "# --- PREVIS√ÉO COM SANEAMENTO AT√îMICO ---\n",
    "print(\"üîÆ Saneando dados e gerando previs√µes...\")\n",
    "\n",
    "# 1. Executa o Saneamento At√¥mico (Garante colunas 1D puras)\n",
    "clean_dict = {}\n",
    "for col in df_inference_final.columns.unique():\n",
    "    col_name = str(col).strip()\n",
    "    series_data = df_inference_final[col]\n",
    "    # Se houver colunas duplicadas vindas do merge, pega a primeira\n",
    "    if isinstance(series_data, pd.DataFrame):\n",
    "        series_data = series_data.iloc[:, 0]\n",
    "    clean_dict[col_name] = series_data.values.flatten()\n",
    "\n",
    "df_inference_cleaned = pd.DataFrame(clean_dict)\n",
    "\n",
    "# 2. Chama o modelo usando o DataFrame limpo\n",
    "forecast_df = loaded_model.predict(df_inference_cleaned)\n",
    "\n",
    "# 3. Adiciona metadados de rastreabilidade\n",
    "forecast_df['version_model'] = mv.version\n",
    "forecast_df['description_model'] = mv.description\n",
    "forecast_df['model_name'] = model_name\n",
    "forecast_df['data_reference'] = datetime.now()\n",
    "\n",
    "print(f\"‚úÖ Previs√£o conclu√≠da para {forecast_df['codigo_loja'].nunique()} lojas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b56cf72d-2dc4-4f8c-8ace-6d9505578e82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 5. PERSIST√äNCIA (WRITE BACK) ---\n",
    "output_table = f\"{config.CATALOG}.{config.SCHEMA}.previsao_lojas_futuro\"\n",
    "\n",
    "print(f\"üíæ Salvando resultados em: {output_table}\")\n",
    "(spark.createDataFrame(forecast_df)\n",
    " .write\n",
    " .format(\"delta\")\n",
    " .mode(\"append\") # Append hist√≥rico de previs√µes\n",
    " .option(\"mergeSchema\", \"true\")\n",
    " .saveAsTable(output_table)\n",
    ")\n",
    "spark.sql(f\"OPTIMIZE {output_table}\")\n",
    "print(\"‚ú® Sucesso! Dados salvos e otimizados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ec49d32-c650-43f6-a25f-3f6fd5c733a3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"description_model\":517},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769530432202}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(forecast_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cvc_inferencia_recorrente",
   "widgets": {
    "catalog": {
     "currentValue": "ds_dev",
     "nuid": "4baaa425-c6d7-4b26-8cbe-ca720f35b0af",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ds_dev",
      "label": "4. Cat√°logo",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ds_dev",
      "label": "4. Cat√°logo",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_treino": {
     "currentValue": "2025-01-01",
     "nuid": "c45fc489-8454-433c-b6cd-13a1372a8ab0",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_validacao": {
     "currentValue": "2025-12-31",
     "nuid": "791a2ba0-ac35-4e45-aca8-90acfe1a63d7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida√ß√£o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida√ß√£o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_inicio_treino": {
     "currentValue": "2019-01-01",
     "nuid": "a8f75fff-84ae-49e1-97f5-2bf352aa6d1d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2019-01-01",
      "label": "1. In√≠cio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2019-01-01",
      "label": "1. In√≠cio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "forecast_horizon": {
     "currentValue": "35",
     "nuid": "4b2598a8-328e-41df-9cc4-a1de1b865d04",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "lags": {
     "currentValue": "5",
     "nuid": "abe2b8ad-b780-4df7-8718-16bba7c59f03",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "n_epochs": {
     "currentValue": "20",
     "nuid": "1487beaf-13b7-4b3a-8fea-729ab40c6e45",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "20",
      "label": "6. √âpocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "20",
      "label": "6. √âpocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}