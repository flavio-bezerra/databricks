{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8da14e6-1b34-43cb-8370-595705ffa6c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üìä Valida√ß√£o de Modelos de S√©ries Temporais - Backtesting (Walk-Forward)\n",
    "\n",
    "## üéØ Objetivo Executivo\n",
    "Este notebook √© respons√°vel pela **valida√ß√£o robusta** dos modelos de previs√£o. Utiliza a metodologia **Walk-Forward** (janela deslizante) para simular o desempenho do modelo no passado.\n",
    "\n",
    "## üõ†Ô∏è Metodologia\n",
    "1.  **Strict Mode**: Garante zero vazamento de dados.\n",
    "2.  **M√∫ltiplos Modelos**: Avalia LightGBM, TFT, Prophet, etc.\n",
    "3.  **M√©tricas**: Calcula RMSE e MAPE.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Valida√ß√£o de Modelos de S√©ries Temporais - CVC Lojas\n",
    "\n",
    "## üéØ Objetivo Executivo\n",
    "Este notebook tem como objetivo realizar a **valida√ß√£o robusta (Backtesting)** de m√∫ltiplos algoritmos de previs√£o de vendas para as lojas da CVC. O processo simula cen√°rios reais do passado para garantir que o modelo escolhido tenha performance consistente ao longo do tempo, e n√£o apenas em um √∫nico per√≠odo de teste.\n",
    "\n",
    "## üõ†Ô∏è Metodologia: Walk-Forward Validation (Strict Mode)\n",
    "Diferente da divis√£o tradicional (Treino/Teste), utilizamos a estrat√©gia de **Walk-Forward** (Janela Deslizante):\n",
    "1.  O modelo treina com dados at√© uma data de corte (ex: Dez/2024).\n",
    "2.  Faz a previs√£o para o m√™s seguinte (ex: Jan/2025).\n",
    "3.  A janela avan√ßa 1 m√™s, o modelo retreina com os dados reais de Jan/2025 e prev√™ Fev/2025.\n",
    "4.  Isso se repete por 12 meses (Folds), gerando m√©tricas de erro (RMSE, SMAPE) para cada m√™s.\n",
    "\n",
    "> **Nota:** O modo \"Strict\" garante que **nenhum dado do futuro** (vazamento de dados) seja acess√≠vel ao modelo durante o treino, simulando fielmente a produ√ß√£o.\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Estrat√©gia de Modelos (Model)\n",
    "A pipeline avalia automaticamente duas classes de algoritmos via biblioteca **Darts**:\n",
    "\n",
    "### 1. Machine Learning Cl√°ssico (Regressores)\n",
    "* **Linear Regression:** Baseline simples para capturar tend√™ncias lineares.\n",
    "* **Random Forest:** Captura n√£o-linearidades e intera√ß√µes complexas.\n",
    "* **LightGBM / XGBoost / CatBoost:** Modelos baseados em *Gradient Boosting*, estado da arte para dados tabulares e s√©ries temporais com covari√°veis.\n",
    "\n",
    "### 2. Deep Learning (SOTA - State of the Art)\n",
    "* **TFT (Temporal Fusion Transformer):** Modelo de aten√ß√£o que aprende a import√¢ncia de cada vari√°vel ao longo do tempo.\n",
    "* **N-BEATS:** Rede neural baseada em blocos de tend√™ncia e sazonalidade.\n",
    "* **Transformer:** Arquitetura cl√°ssica de *Attention* adaptada para s√©ries temporais.\n",
    "* **BlockRNN (LSTM):** Redes recorrentes para capturar depend√™ncias de longo prazo.\n",
    "* **TCN (Temporal Convolutional Network):** Convolu√ß√µes causais para capturar padr√µes locais e globais.\n",
    "\n",
    "---\n",
    "\n",
    "## üèõÔ∏è Arquitetura e Governan√ßa (Databricks Unity Catalog)\n",
    "Este notebook implementa uma arquitetura h√≠brida para conformidade com o Unity Catalog:\n",
    "\n",
    "| Componente | Local de Armazenamento | Fun√ß√£o |\n",
    "| :--- | :--- | :--- |\n",
    "| **Experimentos** | `Workspace/Users/...` | Armazena m√©tricas, gr√°ficos e logs de execu√ß√£o (evita erro de path do UC). |\n",
    "| **Registro de Modelos** | **Unity Catalog** (`ds_dev.cvc_val`) | O modelo final (`.pkl`) √© versionado e governado oficialmente no cat√°logo. |\n",
    "| **Assinatura (Signature)** | **Enforced** | Todos os modelos possuem contrato de entrada/sa√≠da (`long` -> `double`) validado para evitar erros de tipagem no serving. |\n",
    "\n",
    "## üì• Dados de Entrada\n",
    "* **Target:** `bip_vhistorico_targuet_loja` (Vendas hist√≥ricas).\n",
    "* **Covari√°veis Futuras:** `bip_vhistorico_feriados_loja` (Calend√°rio nacional/regional).\n",
    "* **Covari√°veis Globais:** `bip_vhistorico_suporte_canal_loja` (Indicadores macroecon√¥micos e campanhas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "774daccd-6645-45de-9862-6f99b290b5b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configura√ß√£o de otimiza√ß√£o do Spark (Delta Lake)\n",
    "# --- CONFIGURA√á√ïES GLOBAIS DE OTIMIZA√á√ÉO (BEST PRACTICES) ---\n",
    "# Ativa otimiza√ß√£o autom√°tica de grava√ß√µes e compacta√ß√£o\n",
    "spark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.databricks.delta.autoCompact.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c73be932-bbbc-4f6f-ad37-d46f95b893d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importa√ß√£o de bibliotecas essenciais\n",
    "# --- IMPORTS (REFATORED) ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from src.validation.config import Config\n",
    "from src.validation.data import DataIngestion \n",
    "from src.validation.pipeline import ProjectPipeline\n",
    "from src.validation.trainer import ModelTrainer\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.pipeline import Pipeline\n",
    "from darts.dataprocessing.transformers import (\n",
    "    Scaler,\n",
    "    StaticCovariatesTransformer,\n",
    "    MissingValuesFiller\n",
    ")\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.models import (\n",
    "    TFTModel,\n",
    "    NBEATSModel,\n",
    "    TransformerModel,\n",
    "    LinearRegressionModel,\n",
    "    LightGBMModel,\n",
    "    XGBModel,\n",
    "    CatBoostModel,\n",
    "    RandomForest,\n",
    "    BlockRNNModel,\n",
    "    RNNModel,\n",
    "    TCNModel\n",
    ")\n",
    "from darts.metrics import mape, mse, rmse, r2_score, smape\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# Bibliotecas Padr√£o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "\n",
    "# Ingest√£o Imports\n",
    "from databricks.feature_engineering import FeatureEngineeringClient, FeatureLookup\n",
    "import pyspark.sql.functions as F\n",
    "from darts import TimeSeries\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1043f186-666d-4f0e-8f11-891ede540dba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Inicializa√ß√£o da configura√ß√£o centralizada (par√¢metros do widget)\n",
    "if spark is None:\n",
    "    raise RuntimeError(\"Spark Session not available.\")\n",
    "\n",
    "config = Config()\n",
    "config.spark_session = spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80a8e7b9-0a83-4c59-a238-e0760794b623",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"‚è±Ô∏è PER√çODO DE TREINO: {config.DATA_START} at√© {config.TRAIN_END_DATE}\")\n",
    "print(f\"üì• PER√çODO DE INGEST√ÉO (Covari√°veis): At√© {config.INGESTION_END}\")\n",
    "print(f\"üîç JANELA DE TESTE (BACKTEST): {config.VAL_START_DATE} at√© {config.TRAIN_END_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf0d6830-6ac9-4d06-a05d-0326b1c0409c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Instancia√ß√£o da classe de Ingest√£o: Prepara os dados brutos e Feature Store\n",
    "# --- EXECU√á√ÉO DO PIPELINE (OTIMIZADO COM FEATURE STORE) ---\n",
    "print(f\"üöÄ Iniciando Pipeline v{config.VERSION} (Walk-Forward Strict Mode)\")\n",
    "ingestion = DataIngestion(spark, config)\n",
    "\n",
    "# No bloco de execu√ß√£o:\n",
    "# 1. Busca Unificada (Feature Store + Spark ETL)\n",
    "df_spark_wide = ingestion.create_training_set() # Retorna Spark DF\n",
    "df_support_global = ingestion.get_global_support() # Retorna Pandas (pois √© pequeno)\n",
    "\n",
    "# 2. Constru√ß√£o dos Objetos Darts (Aqui ocorre o toPandas)\n",
    "raw_series, raw_covs = ingestion.build_darts_objects(df_spark_wide, df_support_global)\n",
    "\n",
    "# --- Daqui para baixo, o c√≥digo original de treino se mant√©m igual ---\n",
    "# 3. SPLIT DE TREINO\n",
    "train_cutoff_date = pd.Timestamp(config.TRAIN_END_DATE) - pd.Timedelta(days=1)\n",
    "print(f\"‚úÇÔ∏è Data corte para treino est√°tico: {train_cutoff_date.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f12d28c5-c371-4d4e-a9b1-5ecafe7154e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline de pr√©-processamento: Normaliza os dados (0 a 1)\n",
    "print(\"üõ†Ô∏è Ajustando Pipeline (Scalers)...\")\n",
    "project_pipeline = ProjectPipeline()\n",
    "\n",
    "# Define a data de corte (train_cutoff_date j√° deve estar definida como 2024-12-31)\n",
    "# Filtramos apenas s√©ries que possuem dados ANTES da data de corte\n",
    "train_for_fit = [\n",
    "    s.drop_after(train_cutoff_date) \n",
    "    for s in raw_series \n",
    "    if s.start_time() <= train_cutoff_date\n",
    "]\n",
    "\n",
    "# Sincronizamos as covari√°veis para as mesmas lojas v√°lidas\n",
    "cov_for_fit = [\n",
    "    c.drop_after(train_cutoff_date) \n",
    "    for s, c in zip(raw_series, raw_covs) \n",
    "    if s.start_time() <= train_cutoff_date\n",
    "]\n",
    "if not train_for_fit:\n",
    "    raise ValueError(\"Nenhuma loja possui hist√≥rico anterior a \" + str(train_cutoff_date))\n",
    "\n",
    "print(f\"‚úÖ Ajustando Scalers com {len(train_for_fit)} lojas que possuem hist√≥rico.\")\n",
    "project_pipeline.fit(train_for_fit, cov_for_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c242b130-aea4-404a-87c1-7eca58b08082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline de pr√©-processamento: Normaliza os dados (0 a 1)\n",
    "# --- AJUSTE DO PIPELINE (SCALERS) ---\n",
    "print(\"üõ†Ô∏è Ajustando Pipeline (Scalers) em TODAS as s√©ries...\")\n",
    "project_pipeline = ProjectPipeline()\n",
    "\n",
    "# Com a Reindexa√ß√£o Universal, TODAS as s√©ries possuem o ponto 'train_cutoff_date'\n",
    "train_for_fit = [s.drop_after(train_cutoff_date) for s in raw_series]\n",
    "cov_for_fit = [c.drop_after(train_cutoff_date) for c in raw_covs]\n",
    "\n",
    "# O fit agora aprende a escala global (considerando zeros das lojas novas)\n",
    "project_pipeline.fit(train_for_fit, cov_for_fit)\n",
    "\n",
    "print(\"üîÑ Transformando s√©ries (Scaling)...\")\n",
    "series_scaled_full, cov_scaled_full = project_pipeline.transform(raw_series, raw_covs)\n",
    "\n",
    "# Criando as fatias de treino est√°tico para os modelos\n",
    "train_series_static = [s.drop_after(train_cutoff_date) for s in series_scaled_full]\n",
    "train_cov_static = [c.drop_after(train_cutoff_date) for c in cov_scaled_full]\n",
    "\n",
    "print(\"üîÑ Preparando targets originais para invers√£o de escala na valida√ß√£o...\")\n",
    "# Agora usamos a lista completa diretamente\n",
    "val_series_original = project_pipeline.inverse_transform(series_scaled_full, partial=True)\n",
    "\n",
    "# --- 4. CONFIGURA√á√ÉO DE MODELOS ---\n",
    "lag = config.LAGS\n",
    "lag_covariantes = config.LAGS_FUTURE\n",
    "forecast = config.FORECAST_HORIZON\n",
    "lag_2 = lag + config.FORECAST_HORIZON\n",
    "dynamic_kernel = 3\n",
    "EARLY_STOPPER = EarlyStopping(monitor=\"train_loss\", patience=5, min_delta=0.001, mode='min')\n",
    "\n",
    "models_dict = {\n",
    "    \"LinearRegression\": LinearRegressionModel(\n",
    "        lags=lag, lags_future_covariates=lag_covariantes, \n",
    "        output_chunk_length=forecast, multi_models=True\n",
    "    ),\n",
    "    \"RandomForest\": RandomForest(\n",
    "        lags=lag, lags_future_covariates=lag_covariantes, \n",
    "        output_chunk_length=forecast, multi_models=False, random_state=42\n",
    "    ),\n",
    "    \"LightGBM\": LightGBMModel(\n",
    "        lags=lag, lags_future_covariates=lag_covariantes, \n",
    "        output_chunk_length=forecast, multi_models=True, random_state=42,\n",
    "        device=\"gpu\"  # Ativa GPU no LightGBM\n",
    "    ),\n",
    "    \"XGBoost\": XGBModel(\n",
    "        lags=lag, lags_future_covariates=lag_covariantes, \n",
    "        output_chunk_length=forecast, multi_models=True, random_state=42,\n",
    "        device=\"cuda\" # Ativa GPU no XGBoost\n",
    "    ),\n",
    "    \"CatBoost\": CatBoostModel(\n",
    "        lags=lag, lags_future_covariates=lag_covariantes, \n",
    "        output_chunk_length=forecast, multi_models=True, random_state=42,\n",
    "        task_type=\"GPU\" # Ativa GPU no CatBoost\n",
    "    )\n",
    "}\n",
    "\n",
    "if config.N_EPOCHS > 0:\n",
    "    # Configura√ß√£o para modelos PyTorch (TFT, NBEATS, etc.)\n",
    "    pl_trainer_kwargs = {\n",
    "        \"accelerator\": \"gpu\", \n",
    "        \"devices\": 1, \n",
    "        \"callbacks\": [EARLY_STOPPER]\n",
    "    }\n",
    "    \n",
    "    models_dict.update({\n",
    "        \"TFT\": TFTModel(\n",
    "            input_chunk_length=lag_2, output_chunk_length=forecast,\n",
    "            hidden_size=128, lstm_layers=2, num_attention_heads=4,\n",
    "            dropout=0.2, batch_size=4, n_epochs=config.N_EPOCHS,\n",
    "            add_relative_index=True, random_state=42, pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"NBEATS\": NBEATSModel(\n",
    "            input_chunk_length=lag_2, output_chunk_length=forecast,\n",
    "            generic_architecture=True, num_stacks=3, num_blocks=3,\n",
    "            num_layers=4, layer_widths=256, batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS, random_state=42, pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"Transformer\": TransformerModel(\n",
    "            input_chunk_length=lag_2, output_chunk_length=forecast,\n",
    "            d_model=128, nhead=4, num_encoder_layers=3,\n",
    "            num_decoder_layers=3, dim_feedforward=256, dropout=0.2,\n",
    "            batch_size=4, n_epochs=config.N_EPOCHS, random_state=42, pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"BlockRNN\": BlockRNNModel(\n",
    "            model='LSTM', input_chunk_length=lag_2, output_chunk_length=forecast,\n",
    "            hidden_dim=128, n_rnn_layers=2, dropout=0.2,\n",
    "            batch_size=4, n_epochs=config.N_EPOCHS, random_state=42, pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"TCN\": TCNModel(\n",
    "            input_chunk_length=lag_2, output_chunk_length=forecast,\n",
    "            kernel_size=dynamic_kernel, num_filters=lag_2,\n",
    "            num_layers=None, dilation_base=2, dropout=0.2,\n",
    "            batch_size=4, n_epochs=config.N_EPOCHS, random_state=42, pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        )\n",
    "    })\n",
    "\n",
    "# --- IN√çCIO DO TREINO E VALIDA√á√ÉO ---\n",
    "trainer = ModelTrainer(config, models_dict)\n",
    "trainer.train_evaluate_walkforward(\n",
    "    train_series_static=train_series_static,\n",
    "    train_covs_static=train_cov_static,\n",
    "    full_series_scaled=series_scaled_full,    # Lista completa escalonada\n",
    "    full_covariates_scaled=cov_scaled_full,   # Lista completa escalonada\n",
    "    val_series_original=val_series_original, # Lista completa original (para erro real)\n",
    "    target_pipeline=project_pipeline\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Processo Finalizado com Sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Shared/data_science/projetos/cvc_curva_de_vendas_por_canal/environments_dev/requirements.txt"
    ],
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4,
    "widgetLayout": []
   },
   "notebookName": "cvc_validacao_modelos_lojas",
   "widgets": {
    "catalog": {
     "currentValue": "ds_dev",
     "nuid": "29272a53-8157-4b92-aac7-7fc5f0bcf225",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ds_dev",
      "label": "4. Cat√°logo",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ds_dev",
      "label": "4. Cat√°logo",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_treino": {
     "currentValue": "2025-01-01",
     "nuid": "9c57231a-8bfd-42dc-9982-58ae90e52eae",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_validacao": {
     "currentValue": "2025-12-31",
     "nuid": "eba7ab02-00ae-4b85-9614-72adca31086a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida√ß√£o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida√ß√£o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_inicio_treino": {
     "currentValue": "2019-01-01",
     "nuid": "bca3de28-8ed0-48fb-9743-a6436500f256",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2019-01-01",
      "label": "1. In√≠cio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2019-01-01",
      "label": "1. In√≠cio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "forecast_horizon": {
     "currentValue": "35",
     "nuid": "7aa7ecb8-dfb6-4055-953f-49ca4ad20576",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "lags": {
     "currentValue": "5",
     "nuid": "b5d1dfdd-fdcf-4649-a76c-20f30747489d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "n_epochs": {
     "currentValue": "20",
     "nuid": "9b95a973-2056-45d5-ad25-b42f6e98255a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "20",
      "label": "6. √âpocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "20",
      "label": "6. √âpocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
