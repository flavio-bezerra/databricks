{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8da14e6-1b34-43cb-8370-595705ffa6c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \ud83d\udcca Valida\u00e7\u00e3o de Modelos de S\u00e9ries Temporais - CVC Lojas\n",
    "\n",
    "## \ud83c\udfaf Objetivo Executivo\n",
    "Este notebook tem como objetivo realizar a **valida\u00e7\u00e3o robusta (Backtesting)** de m\u00faltiplos algoritmos de previs\u00e3o de vendas para as lojas da CVC. O processo simula cen\u00e1rios reais do passado para garantir que o modelo escolhido tenha performance consistente ao longo do tempo, e n\u00e3o apenas em um \u00fanico per\u00edodo de teste.\n",
    "\n",
    "## \ud83d\udee0\ufe0f Metodologia: Walk-Forward Validation (Strict Mode)\n",
    "Diferente da divis\u00e3o tradicional (Treino/Teste), utilizamos a estrat\u00e9gia de **Walk-Forward** (Janela Deslizante):\n",
    "1.  O modelo treina com dados at\u00e9 uma data de corte (ex: Dez/2024).\n",
    "2.  Faz a previs\u00e3o para o m\u00eas seguinte (ex: Jan/2025).\n",
    "3.  A janela avan\u00e7a 1 m\u00eas, o modelo retreina com os dados reais de Jan/2025 e prev\u00ea Fev/2025.\n",
    "4.  Isso se repete por 12 meses (Folds), gerando m\u00e9tricas de erro (RMSE, SMAPE) para cada m\u00eas.\n",
    "\n",
    "> **Nota:** O modo \"Strict\" garante que **nenhum dado do futuro** (vazamento de dados) seja acess\u00edvel ao modelo durante o treino, simulando fielmente a produ\u00e7\u00e3o.\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83e\udd16 Estrat\u00e9gia de Modelos (Model)\n",
    "A pipeline avalia automaticamente duas classes de algoritmos via biblioteca **Darts**:\n",
    "\n",
    "### 1. Machine Learning Cl\u00e1ssico (Regressores)\n",
    "* **Linear Regression:** Baseline simples para capturar tend\u00eancias lineares.\n",
    "* **Random Forest:** Captura n\u00e3o-linearidades e intera\u00e7\u00f5es complexas.\n",
    "* **LightGBM / XGBoost / CatBoost:** Modelos baseados em *Gradient Boosting*, estado da arte para dados tabulares e s\u00e9ries temporais com covari\u00e1veis.\n",
    "\n",
    "### 2. Deep Learning (SOTA - State of the Art)\n",
    "* **TFT (Temporal Fusion Transformer):** Modelo de aten\u00e7\u00e3o que aprende a import\u00e2ncia de cada vari\u00e1vel ao longo do tempo.\n",
    "* **N-BEATS:** Rede neural baseada em blocos de tend\u00eancia e sazonalidade.\n",
    "* **Transformer:** Arquitetura cl\u00e1ssica de *Attention* adaptada para s\u00e9ries temporais.\n",
    "* **BlockRNN (LSTM):** Redes recorrentes para capturar depend\u00eancias de longo prazo.\n",
    "* **TCN (Temporal Convolutional Network):** Convolu\u00e7\u00f5es causais para capturar padr\u00f5es locais e globais.\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udfdb\ufe0f Arquitetura e Governan\u00e7a (Databricks Unity Catalog)\n",
    "Este notebook implementa uma arquitetura h\u00edbrida para conformidade com o Unity Catalog:\n",
    "\n",
    "| Componente | Local de Armazenamento | Fun\u00e7\u00e3o |\n",
    "| :--- | :--- | :--- |\n",
    "| **Experimentos** | `Workspace/Users/...` | Armazena m\u00e9tricas, gr\u00e1ficos e logs de execu\u00e7\u00e3o (evita erro de path do UC). |\n",
    "| **Registro de Modelos** | **Unity Catalog** (`ds_dev.cvc_val`) | O modelo final (`.pkl`) \u00e9 versionado e governado oficialmente no cat\u00e1logo. |\n",
    "| **Assinatura (Signature)** | **Enforced** | Todos os modelos possuem contrato de entrada/sa\u00edda (`long` -> `double`) validado para evitar erros de tipagem no serving. |\n",
    "\n",
    "## \ud83d\udce5 Dados de Entrada\n",
    "* **Target:** `bip_vhistorico_targuet_loja` (Vendas hist\u00f3ricas).\n",
    "* **Covari\u00e1veis Futuras:** `bip_vhistorico_feriados_loja` (Calend\u00e1rio nacional/regional).\n",
    "* **Covari\u00e1veis Globais:** `bip_vhistorico_suporte_canal_loja` (Indicadores macroecon\u00f4micos e campanhas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURA\u00c7\u00d5ES GLOBAIS DE OTIMIZA\u00c7\u00c3O (BEST PRACTICES) ---\n",
    "# Ativa otimiza\u00e7\u00e3o autom\u00e1tica de grava\u00e7\u00f5es e compacta\u00e7\u00e3o\n",
    "spark.conf.set(\"spark.databricks.delta.optimizeWrite.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.databricks.delta.autoCompact.enabled\", \"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c73be932-bbbc-4f6f-ad37-d46f95b893d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- IMPORTS (REFATORED) ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from src.validation.config import Config\n",
    "# from src.validation.data import DataIngestion \n",
    "from src.validation.pipeline import ProjectPipeline\n",
    "from src.validation.trainer import ModelTrainer\n",
    "\n",
    "# Bibliotecas Padr\u00e3o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "\n",
    "# Ingest\u00e3o Imports\n",
    "from databricks.feature_engineering import FeatureEngineeringClient, FeatureLookup\n",
    "import pyspark.sql.functions as F\n",
    "from darts import TimeSeries\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "\n",
    "# --- CLASSE DE INGEST\u00c3O OTIMIZADA ---\n",
    "class DataIngestion:\n",
    "    def __init__(self, spark_session, config):\n",
    "        self.spark = spark_session\n",
    "        self.config = config\n",
    "        self.fe = FeatureEngineeringClient()\n",
    "\n",
    "    def create_training_set(self):\n",
    "        \"\"\"\n",
    "        Gera o dataset completo via Feature Store e realiza ETL nativo no Spark.\n",
    "        Retorna: DataFrame PySpark (Lazy Evaluation)\n",
    "        \"\"\"\n",
    "        print(\"\ud83d\uded2 Construindo Training Set via Feature Store (Spark Native)...\")\n",
    "\n",
    "        # 1. Definir a 'Spine' (Target)\n",
    "        target_table = f\"{self.config.CATALOG}.{self.config.SCHEMA}.bip_vhistorico_targuet_loja\"\n",
    "        \n",
    "        df_spine = (self.spark.table(target_table)\n",
    "                    .filter(F.col(\"DATA\").between(self.config.DATA_START, self.config.INGESTION_END))\n",
    "                    .select(\"CODIGO_LOJA\", \"DATA\", \"VALOR\")\n",
    "                    .withColumnRenamed(\"VALOR\", \"TARGET_VENDAS\")\n",
    "                    .withColumn(\"CODIGO_LOJA\", F.col(\"CODIGO_LOJA\").cast(\"string\"))\n",
    "                   )\n",
    "\n",
    "        # 2. Configurar Lookups\n",
    "        feature_lookups = [\n",
    "            FeatureLookup(\n",
    "                table_name=f\"{self.config.CATALOG}.{self.config.SCHEMA}.cmc_alojas\",\n",
    "                lookup_key=[\"CODIGO_LOJA\"],\n",
    "                feature_names=[\"CLUSTER_LOJA\", \"SIGLA_UF\", \"TIPO_LOJA\", \"MODELO_LOJA\"]\n",
    "            ),\n",
    "            FeatureLookup(\n",
    "                table_name=f\"{self.config.CATALOG}.{self.config.SCHEMA}.bip_vhistorico_feriados_loja\",\n",
    "                lookup_key=[\"CODIGO_LOJA\"],\n",
    "                timestamp_lookup_key=\"DATA\",\n",
    "                feature_names=[\"VALOR\"], \n",
    "                output_name=\"IS_FERIADO\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 3. Criar Training Set (Retorna objeto FeatureEngineeringTrainingSet)\n",
    "        training_set = self.fe.create_training_set(\n",
    "            df=df_spine,\n",
    "            feature_lookups=feature_lookups,\n",
    "            label=\"TARGET_VENDAS\",\n",
    "            exclude_columns=[]\n",
    "        )\n",
    "\n",
    "        # 4. Carregar como DataFrame Spark (SEM toPandas aqui)\n",
    "        df_spark = training_set.load_df()\n",
    "\n",
    "        # --- ETL NATIVO NO SPARK (Distribu\u00eddo) ---\n",
    "        print(\"   \u26a1 Executando limpeza e tratamento no Spark Cluster...\")\n",
    "        \n",
    "        # A. Tratamento de Nulos (Left Joins geram nulos)\n",
    "        # Sintaxe Spark: fill(valor, subset=[colunas]) ou fill({col: val})\n",
    "        df_spark = df_spark.na.fill({\n",
    "            \"IS_FERIADO\": 0.0, \n",
    "            \"TARGET_VENDAS\": 0.0,\n",
    "            \"CLUSTER_LOJA\": \"DESCONHECIDO\",\n",
    "            \"SIGLA_UF\": \"DESCONHECIDO\",\n",
    "            \"TIPO_LOJA\": \"DESCONHECIDO\",\n",
    "            \"MODELO_LOJA\": \"DESCONHECIDO\"\n",
    "        })\n",
    "\n",
    "        # B. Garantia de Tipos (Casting)\n",
    "        df_spark = df_spark.withColumn(\"DATA\", F.to_timestamp(\"DATA\"))\n",
    "        \n",
    "        return df_spark\n",
    "\n",
    "    def get_global_support(self):\n",
    "        \"\"\"\n",
    "        Carrega suporte global mantendo processamento no Spark at\u00e9 o final.\n",
    "        \"\"\"\n",
    "        table_name = \"bip_vhistorico_suporte_canal_loja\"\n",
    "        print(f\"\ud83c\udf0d Carregando suporte global (Spark Aggregation)...\")\n",
    "        \n",
    "        # Toda a agrega\u00e7\u00e3o ocorre no cluster\n",
    "        df_spark = (self.spark.table(f\"{self.config.CATALOG}.{self.config.SCHEMA}.{table_name}\")\n",
    "            .filter(F.col(\"DATA\").between(self.config.DATA_START, self.config.INGESTION_END))\n",
    "            .groupBy(\"DATA\")\n",
    "            .pivot(\"METRICAS\")\n",
    "            .agg(F.sum(\"VALOR\"))\n",
    "            .na.fill(0.0) # Preenche nulos do pivot no Spark\n",
    "        )\n",
    "        \n",
    "        # S\u00f3 converte o resultado final (pequeno) para Pandas\n",
    "        pdf = df_spark.toPandas()\n",
    "        pdf['DATA'] = pd.to_datetime(pdf['DATA'])\n",
    "        return pdf.set_index('DATA').asfreq('D').fillna(0.0)\n",
    "\n",
    "    def build_darts_objects(self, df_spark_wide, df_global_support):\n",
    "        \"\"\"\n",
    "        Recebe Spark DataFrame -> Converte para Pandas -> Cria objetos Darts\n",
    "        \"\"\"\n",
    "        print(\"\u2699\ufe0f Materializando dados do Spark para Pandas (Driver)...\")\n",
    "\n",
    "        # AQUI acontece a transfer\u00eancia de dados Cluster -> Driver\n",
    "        # Como j\u00e1 filtramos e limpamos no Spark, o dado vem menor e mais limpo.\n",
    "        df_wide = df_spark_wide.toPandas()\n",
    "        \n",
    "        # Garante tipos Pandas compat\u00edveis com Darts\n",
    "        df_wide['DATA'] = pd.to_datetime(df_wide['DATA'])\n",
    "        \n",
    "        # Identifica\u00e7\u00e3o din\u00e2mica de colunas est\u00e1ticas\n",
    "        possible_static = [\"CLUSTER_LOJA\", \"SIGLA_UF\", \"TIPO_LOJA\", \"MODELO_LOJA\"]\n",
    "        static_cols = [c for c in possible_static if c in df_wide.columns]\n",
    "\n",
    "        print(\"   Build: Criando Target Series...\")\n",
    "        target_series_list = TimeSeries.from_group_dataframe(\n",
    "            df_wide,\n",
    "            group_cols=\"CODIGO_LOJA\",\n",
    "            time_col=\"DATA\",\n",
    "            value_cols=\"TARGET_VENDAS\",\n",
    "            static_cols=static_cols,\n",
    "            freq='D',\n",
    "            fill_missing_dates=True,\n",
    "            fillna_value=0.0\n",
    "        )\n",
    "        \n",
    "        target_dict = {str(ts.static_covariates.index[0]): ts for ts in target_series_list}\n",
    "        valid_stores = list(target_dict.keys())\n",
    "\n",
    "        print(\"   Build: Criando Covari\u00e1veis Locais...\")\n",
    "        feriado_series_list = TimeSeries.from_group_dataframe(\n",
    "            df_wide,\n",
    "            group_cols=\"CODIGO_LOJA\",\n",
    "            time_col=\"DATA\",\n",
    "            value_cols=[\"IS_FERIADO\"], \n",
    "            freq='D',\n",
    "            fill_missing_dates=True,\n",
    "            fillna_value=0.0\n",
    "        )\n",
    "        feriado_dict = {str(ts.static_covariates[\"CODIGO_LOJA\"].iloc[0]): ts for ts in feriado_series_list}\n",
    "\n",
    "        # Globais (j\u00e1 vieram prontas do m\u00e9todo get_global_support)\n",
    "        ts_support = TimeSeries.from_dataframe(\n",
    "            df_global_support, \n",
    "            fill_missing_dates=True, \n",
    "            freq='D',\n",
    "            fillna_value=0.0\n",
    "        )\n",
    "        \n",
    "        ts_time = datetime_attribute_timeseries(df_global_support.index, attribute=\"dayofweek\", cyclic=True)\n",
    "        ts_time = ts_time.stack(datetime_attribute_timeseries(df_global_support.index, attribute=\"quarter\", one_hot=True))\n",
    "        ts_time = ts_time.stack(datetime_attribute_timeseries(df_global_support.index, attribute=\"week\", cyclic=True))\n",
    "        \n",
    "        global_covariates = ts_support.stack(ts_time)\n",
    "\n",
    "        final_target_list = []\n",
    "        full_covariates_list = []\n",
    "\n",
    "        print(\"   Build: Stacking Final...\")\n",
    "        for loja in valid_stores:\n",
    "            ts_target = target_dict[loja]\n",
    "            final_target_list.append(ts_target)\n",
    "            \n",
    "            ts_local = feriado_dict.get(loja)\n",
    "            if ts_local:\n",
    "                 ts_local = ts_local.slice_intersect(ts_target)\n",
    "            else:\n",
    "                 ts_local = TimeSeries.from_times_and_values(ts_target.time_index, np.zeros(len(ts_target)), freq='D')\n",
    "            \n",
    "            ts_global = global_covariates.slice_intersect(ts_target)\n",
    "            full_covariates_list.append(ts_global.stack(ts_local))\n",
    "\n",
    "        print(f\"\u2705 Objetos Darts Prontos: {len(final_target_list)} lojas.\")\n",
    "        return final_target_list, full_covariates_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1043f186-666d-4f0e-8f11-891ede540dba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if spark is None:\n",
    "    raise RuntimeError(\"Spark Session not available.\")\n",
    "\n",
    "config = Config()\n",
    "config.spark_session = spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486a3118-319e-4a68-af2c-b8d94be26aac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\ude80 Iniciando Pipeline v2026_01_15_09_42 (Walk-Forward Strict Mode)\n\ud83d\uded2 Construindo Training Set via Feature Store (Spark Native)...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:42:41 WARNING databricks.ml_features.entities.feature_lookup: The output_name parameter is deprecated.  Use \"rename_outputs\".\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \u26a1 Executando limpeza e tratamento no Spark Cluster...\n\ud83c\udf0d Carregando suporte global (Spark Aggregation)...\n\u2699\ufe0f Materializando dados do Spark para Pandas (Driver)...\n   Build: Criando Target Series...\n   Build: Criando Covari\u00e1veis Locais...\n   Build: Stacking Final...\n\u2705 Objetos Darts Prontos: 1 lojas.\n\u2702\ufe0f Data corte para treino est\u00e1tico: 2024-12-31\n\ud83d\udee0\ufe0f Ajustando Pipeline (Scalers)...\n\ud83d\udd04 Transformando TODAS as s\u00e9ries...\n\ud83d\udcbe Pipeline salvo: /Volumes/ds_dev/cvc/experiments/artefacts/loja/scalar/validation/project_pipeline_v2026_01_15_09_42.pkl\n\ud83d\udd0d Filtrando s\u00e9ries curtas...\n\ud83d\udd04 Preparando targets originais para valida\u00e7\u00e3o...\n\n\ud83d\ude80 [Model: LinearRegression] Iniciando Processo...\n   \ud83d\udcdd Registrando metadados do experimento...\n   \ud83c\udfcb\ufe0f Treinando com dados at\u00e9 2025-01-01...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:45:51 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcbe Registrando modelo como: ds_dev.cvc.loja_LinearRegression\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bea3bccbad46539319e22c4881499c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddddc8037d2f4f2f8a92a12b9dcb4d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140f2d90c9a643e290847c4804eced67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'ds_dev.cvc.loja_LinearRegression' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1953dacd1e54cd59965770827f9e0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '22' of model 'ds_dev.cvc.loja_linearregression'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udd2e Iniciando Infer\u00eancia Walk-Forward (5 folds)...\n     \ud83d\udcc5 2025-01: SMAPE=200.00%, RMSE=1188891008021282.50\n     \ud83d\udcc5 2025-02: SMAPE=200.00%, RMSE=363331800284236.06\n     \ud83d\udcc5 2025-03: SMAPE=200.00%, RMSE=4394207113599525.50\n     \ud83d\udcc5 2025-04: SMAPE=200.00%, RMSE=9098643977247738.00\n     \ud83d\udcc5 2025-05: SMAPE=200.00%, RMSE=6052933627652242.00\n   \ud83d\udcca GLOBAL: MAPE=inf%, RMSE=5090182958597040.00\n\n\ud83d\ude80 [Model: RandomForest] Iniciando Processo...\n   \ud83d\udcdd Registrando metadados do experimento...\n   \ud83c\udfcb\ufe0f Treinando com dados at\u00e9 2025-01-01...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:45:58 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcbe Registrando modelo como: ds_dev.cvc.loja_RandomForest\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4662cf830f184597922a016a511826eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5e037119914ed5871b97ae80e2a96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af376a736e0748cea202bd2f510c393d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'ds_dev.cvc.loja_RandomForest' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ec076b09064b269c3e333a179f5f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '14' of model 'ds_dev.cvc.loja_randomforest'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udd2e Iniciando Infer\u00eancia Walk-Forward (5 folds)...\n     \ud83d\udcc5 2025-01: SMAPE=116.56%, RMSE=1798.33\n     \ud83d\udcc5 2025-02: SMAPE=133.26%, RMSE=3223.38\n     \ud83d\udcc5 2025-03: SMAPE=96.35%, RMSE=2777.61\n     \ud83d\udcc5 2025-04: SMAPE=94.24%, RMSE=7384.77\n     \ud83d\udcc5 2025-05: SMAPE=111.89%, RMSE=2372.42\n   \ud83d\udcca GLOBAL: MAPE=inf%, RMSE=4355.29\n\n\ud83d\ude80 [Model: LightGBM] Iniciando Processo...\n   \ud83d\udcdd Registrando metadados do experimento...\n   \ud83c\udfcb\ufe0f Treinando com dados at\u00e9 2025-01-01...\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.081850\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000023 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.081165\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000026 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.083318\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000020 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.086238\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain\n\n*** WARNING: max output size exceeded, skipping output. ***\n\nn, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000025 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.177317\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000021 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.176854\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000021 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.177811\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:46:06 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcbe Registrando modelo como: ds_dev.cvc.loja_LightGBM\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1585560c108b4a009d0de3a7f3cd1aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9389d6d1c5d64c22a7080ed12294a0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb41ddf62a4a45e7a7b6b5ad6b7e2020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'ds_dev.cvc.loja_LightGBM' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d1d481d5784bcc92089e7c31514104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '14' of model 'ds_dev.cvc.loja_lightgbm'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udd2e Iniciando Infer\u00eancia Walk-Forward (5 folds)...\n     \ud83d\udcc5 2025-01: SMAPE=101.51%, RMSE=1638.61\n     \ud83d\udcc5 2025-02: SMAPE=97.22%, RMSE=1630.30\n     \ud83d\udcc5 2025-03: SMAPE=52.19%, RMSE=1264.94\n     \ud83d\udcc5 2025-04: SMAPE=116.66%, RMSE=7850.24\n     \ud83d\udcc5 2025-05: SMAPE=84.25%, RMSE=1551.38\n   \ud83d\udcca GLOBAL: MAPE=inf%, RMSE=4140.33\n\n\ud83d\ude80 [Model: XGBoost] Iniciando Processo...\n   \ud83d\udcdd Registrando metadados do experimento...\n   \ud83c\udfcb\ufe0f Treinando com dados at\u00e9 2025-01-01...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:46:16 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcbe Registrando modelo como: ds_dev.cvc.loja_XGBoost\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3100f235a6644bfb8bdb6f0efdbc5515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4286b8f02e94cb798320bdf906fc167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25fccf88ae54d9fabbbd73a7609f6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'ds_dev.cvc.loja_XGBoost' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3b76b13e6f438da7d56c49829c00d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '17' of model 'ds_dev.cvc.loja_xgboost'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udd2e Iniciando Infer\u00eancia Walk-Forward (5 folds)...\n     \ud83d\udcc5 2025-01: SMAPE=104.57%, RMSE=3101.59\n     \ud83d\udcc5 2025-02: SMAPE=111.95%, RMSE=3150.04\n     \ud83d\udcc5 2025-03: SMAPE=72.56%, RMSE=2827.61\n     \ud83d\udcc5 2025-04: SMAPE=113.52%, RMSE=8080.54\n     \ud83d\udcc5 2025-05: SMAPE=103.10%, RMSE=2897.66\n   \ud83d\udcca GLOBAL: MAPE=inf%, RMSE=4817.50\n\n\ud83d\ude80 [Model: CatBoost] Iniciando Processo...\n   \ud83d\udcdd Registrando metadados do experimento...\n   \ud83c\udfcb\ufe0f Treinando com dados at\u00e9 2025-01-01...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:48:01 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcbe Registrando modelo como: ds_dev.cvc.loja_CatBoost\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99db2821d97247b1835c833d96d9531d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb99a01ef554a058cb10d88c075eae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0aade23fa142a7aa2cd796c399b99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'ds_dev.cvc.loja_CatBoost' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd38521baf24e91a0b1df1d9d9c46e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '9' of model 'ds_dev.cvc.loja_catboost'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udd2e Iniciando Infer\u00eancia Walk-Forward (5 folds)...\n     \ud83d\udcc5 2025-01: SMAPE=107.15%, RMSE=2533.92\n     \ud83d\udcc5 2025-02: SMAPE=104.32%, RMSE=2131.13\n     \ud83d\udcc5 2025-03: SMAPE=52.62%, RMSE=1209.97\n     \ud83d\udcc5 2025-04: SMAPE=111.42%, RMSE=7889.40\n     \ud83d\udcc5 2025-05: SMAPE=82.69%, RMSE=1396.37\n   \ud83d\udcca GLOBAL: MAPE=inf%, RMSE=4320.57\n\n\ud83d\ude80 [Model: TFT] Iniciando Processo...\n   \ud83d\udcdd Registrando metadados do experimento...\n   \ud83c\udfcb\ufe0f Treinando com dados at\u00e9 2025-01-01...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n   | Name                              | Type                             | Params | Mode \n------------------------------------------------------------------------------------------------\n0  | train_metrics                     | MetricCollection                 | 0      | train\n1  | val_metrics                       | MetricCollection                 | 0      | train\n2  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n3  | static_covariates_vsn             | _VariableSelectionNetwork        | 15.8 K | train\n4  | encoder_vsn                       | _VariableSelectionNetwork        | 583 K  | train\n5  | decoder_vsn                       | _VariableSelectionNetwork        | 247 K  | train\n6  | static_context_grn                | _GatedResidualNetwork            | 66.3 K | train\n7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 66.3 K | train\n8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 66.3 K | train\n9  | static_context_enrichment         | _GatedResidualNetwork            | 66.3 K | train\n10 | lstm_encoder                      | LSTM                             | 264 K  | train\n11 | lstm_decoder                      | LSTM                             | 264 K  | train\n12 | post_lstm_gan                     | _GateAddNorm                     | 33.3 K | train\n13 | static_enrichment_grn             | _GatedResidualNetwork            | 82.7 K | train\n14 | multihead_attn                    | _InterpretableMultiHeadAttention | 41.2 K | train\n15 | post_attn_gan                     | _GateAddNorm                     | 33.3 K | train\n16 | feed_forward_block                | _GatedResidualNetwork            | 66.3 K | train\n17 | pre_output_gan                    | _GateAddNorm                     | 33.3 K | train\n18 | output_layer                      | Linear                           | 2.2 K  | train\n------------------------------------------------------------------------------------------------\n1.9 M     Trainable params\n0         Non-trainable params\n1.9 M     Total params\n7.726     Total estimated model params size (MB)\n3004      Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4f89d6f75042fab602d29a785bafb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:48:56 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcbe Registrando modelo como: ds_dev.cvc.loja_TFT\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223e0e084f3e40d5b8acb79ecee46952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4235e05b014fb2a3276b00d2479802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:48:57 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"n\"\n    ],\n    \"data\": [\n      [\n        35\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: A load persistent id instruction was encountered, but no persistent_load function was specified.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46dc8293a004ecca9361a1118b4ba23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'ds_dev.cvc.loja_TFT' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe121447384d4774a704adad1ffb7371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '7' of model 'ds_dev.cvc.loja_tft'.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udd2e Iniciando Infer\u00eancia Walk-Forward (5 folds)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4da34cd4fa496b96e9d15c1e7443a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-01: SMAPE=127.28%, RMSE=3519.47\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3f4010597f49139325ed75aaef4ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-02: SMAPE=162.67%, RMSE=3930.39\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34930821c9d2431a93045d4b3cc834ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-03: SMAPE=108.92%, RMSE=2763.98\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52d354523894a1f969912f025b6f043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:darts.utils.data.inference_dataset:ValueError: For the given forecasting horizon `n=35`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n <= output_chunk_length` the future covariates must end at time step `2025-06-03 00:00:00`, whereas now they end at time step `2025-05-31 00:00:00`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-04: SMAPE=123.23%, RMSE=7542.82\n\u274c Error training TFT: For the given forecasting horizon `n=35`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n <= output_chunk_length` the future covariates must end at time step `2025-06-03 00:00:00`, whereas now they end at time step `2025-05-31 00:00:00`.\n\n\ud83d\ude80 [Model: NBEATS] Iniciando Processo...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Traceback (most recent call last):\n  File \"/root/.ipykernel/9536/command-710650326555544-3165449090\", line 183, in train_evaluate_walkforward\n    preds_scaled = model.predict(**predict_kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/torch.py\", line 103, in decorator\n    return decorated(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1465, in predict\n    predictions = self.predict_from_dataset(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/torch.py\", line 103, in decorator\n    return decorated(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1559, in predict_from_dataset\n    self._verify_predict_sample(input_series_dataset[0])\n                                ~~~~~~~~~~~~~~~~~~~~^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/data/inference_dataset.py\", line 711, in __getitem__\n    _, historic_future_covariate, future_covariate, _, _, _ = self.ds_future[idx]\n                                                              ~~~~~~~~~~~~~~^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/data/inference_dataset.py\", line 599, in __getitem__\n    ) = self.ds_past[idx]\n        ~~~~~~~~~~~~^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/data/inference_dataset.py\", line 418, in __getitem__\n    return self.ds[idx]\n           ~~~~~~~^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/data/inference_dataset.py\", line 291, in __getitem__\n    covariate_start, covariate_end = self._covariate_indexer(\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/data/inference_dataset.py\", line 108, in _covariate_indexer\n    raise_log(\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/logging.py\", line 132, in raise_log\n    raise exception\nValueError: For the given forecasting horizon `n=35`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n <= output_chunk_length` the future covariates must end at time step `2025-06-03 00:00:00`, whereas now they end at time step `2025-05-31 00:00:00`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcdd Registrando metadados do experimento...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name            | Type             | Params | Mode \n-------------------------------------------------------------\n0 | criterion       | MSELoss          | 0      | train\n1 | train_criterion | MSELoss          | 0      | train\n2 | val_criterion   | MSELoss          | 0      | train\n3 | train_metrics   | MetricCollection | 0      | train\n4 | val_metrics     | MetricCollection | 0      | train\n5 | stacks          | ModuleList       | 7.9 M  | train\n-------------------------------------------------------------\n7.8 M     Trainable params\n16.4 K    Non-trainable params\n7.9 M     Total params\n31.452    Total estimated model params size (MB)\n111       Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83c\udfcb\ufe0f Treinando com dados at\u00e9 2025-01-01...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200b524fe55d4accaff414a36934cf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:49:18 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcbe Registrando modelo como: ds_dev.cvc.loja_NBEATS\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4d622259e24b6f8aadfba2dcf56039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:49:19 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"n\"\n    ],\n    \"data\": [\n      [\n        35\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: A load persistent id instruction was encountered, but no persistent_load function was specified.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba8e28f3338459987862173d85f4db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'ds_dev.cvc.loja_NBEATS' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9e5ad4df544546aff396fc4a5147a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '7' of model 'ds_dev.cvc.loja_nbeats'.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udd2e Iniciando Infer\u00eancia Walk-Forward (5 folds)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14641c7827034635ba7268920652f6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-01: SMAPE=126.92%, RMSE=2948.03\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4848e6c388914dad8eecdfc03c86cc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-02: SMAPE=122.74%, RMSE=3004.73\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cceb5a8b0bc241c4881b40b03aad8f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-03: SMAPE=127.73%, RMSE=3826.65\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3a230671ec48e4b05acc13ff7e27a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-04: SMAPE=145.47%, RMSE=10060.44\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3106db2ee004fbeafd474da9716f6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-05: SMAPE=114.09%, RMSE=3050.67\n   \ud83d\udcca GLOBAL: MAPE=inf%, RMSE=5778.73\n\n\ud83d\ude80 [Model: Transformer] Iniciando Processo...\n   \ud83d\udcdd Registrando metadados do experimento...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name                | Type                | Params | Mode \n--------------------------------------------------------------------\n0 | criterion           | MSELoss             | 0      | train\n1 | train_criterion     | MSELoss             | 0      | train\n2 | val_criterion       | MSELoss             | 0      | train\n3 | train_metrics       | MetricCollection    | 0      | train\n4 | val_metrics         | MetricCollection    | 0      | train\n5 | encoder             | Linear              | 8.2 K  | train\n6 | positional_encoding | _PositionalEncoding | 0      | train\n7 | transformer         | Transformer         | 994 K  | train\n8 | decoder             | Linear              | 4.5 K  | train\n--------------------------------------------------------------------\n1.0 M     Trainable params\n0         Non-trainable params\n1.0 M     Total params\n4.028     Total estimated model params size (MB)\n88        Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83c\udfcb\ufe0f Treinando com dados at\u00e9 2025-01-01...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157670bcbf764416931d5d201e84a253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:49:26 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcbe Registrando modelo como: ds_dev.cvc.loja_Transformer\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04591dab631f49b786e192c7ec10a03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:49:27 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"n\"\n    ],\n    \"data\": [\n      [\n        35\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: A load persistent id instruction was encountered, but no persistent_load function was specified.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8d350b6c384ca8ac220b44b54fa035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'ds_dev.cvc.loja_Transformer' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcf955853e84959824535d760be1fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '7' of model 'ds_dev.cvc.loja_transformer'.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udd2e Iniciando Infer\u00eancia Walk-Forward (5 folds)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a735cc2ab7094cb0ae324bf08a7f7a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-01: SMAPE=133.75%, RMSE=2717.40\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695d19eb7cc64b1abb77de9e15fbaf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-02: SMAPE=139.96%, RMSE=2805.05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acae2ef146694f1da84a4f051fbf6259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-03: SMAPE=123.52%, RMSE=2819.38\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d657fc543ad4a8b8b41e70b51a6ed03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-04: SMAPE=134.98%, RMSE=8394.78\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ecd0ea57b946c38fb4666aa6ec7e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-05: SMAPE=121.38%, RMSE=2361.16\n   \ud83d\udcca GLOBAL: MAPE=inf%, RMSE=4839.26\n\n\ud83d\ude80 [Model: BlockRNN] Iniciando Processo...\n   \ud83d\udcdd Registrando metadados do experimento...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name            | Type             | Params | Mode \n-------------------------------------------------------------\n0 | criterion       | MSELoss          | 0      | train\n1 | train_criterion | MSELoss          | 0      | train\n2 | val_criterion   | MSELoss          | 0      | train\n3 | train_metrics   | MetricCollection | 0      | train\n4 | val_metrics     | MetricCollection | 0      | train\n5 | rnn             | LSTM             | 230 K  | train\n6 | fc              | Sequential       | 4.5 K  | train\n-------------------------------------------------------------\n235 K     Trainable params\n0         Non-trainable params\n235 K     Total params\n0.942     Total estimated model params size (MB)\n8         Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83c\udfcb\ufe0f Treinando com dados at\u00e9 2025-01-01...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0375c9a557084544bab190861a9c804d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:49:33 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcbe Registrando modelo como: ds_dev.cvc.loja_BlockRNN\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80bc2d11b224d7cb02eb3a19caf354c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:49:33 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"n\"\n    ],\n    \"data\": [\n      [\n        35\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: A load persistent id instruction was encountered, but no persistent_load function was specified.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b4b067d8634fe7bb2280f0103c2ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'ds_dev.cvc.loja_BlockRNN' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914e85d7ee85413d859eaee5a0e6bb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '7' of model 'ds_dev.cvc.loja_blockrnn'.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udd2e Iniciando Infer\u00eancia Walk-Forward (5 folds)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cda30da462241ffa0ac991c05ab937b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-01: SMAPE=70.23%, RMSE=826.44\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be9a98bd7014bef8ada41765480305f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-02: SMAPE=85.77%, RMSE=1022.56\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8541f7ff59f94de8931f8539507606f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-03: SMAPE=70.35%, RMSE=1192.15\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b166c40c634ff7a149812f6db96b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-04: SMAPE=110.37%, RMSE=7586.78\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f015ffa45a74469080c9ab728abe82d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-05: SMAPE=88.44%, RMSE=1311.85\n   \ud83d\udcca GLOBAL: MAPE=inf%, RMSE=3895.80\n\n\ud83d\ude80 [Model: TCN] Iniciando Processo...\n   \ud83d\udcdd Registrando metadados do experimento...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name            | Type             | Params | Mode \n-------------------------------------------------------------\n0 | criterion       | MSELoss          | 0      | train\n1 | train_criterion | MSELoss          | 0      | train\n2 | val_criterion   | MSELoss          | 0      | train\n3 | train_metrics   | MetricCollection | 0      | train\n4 | val_metrics     | MetricCollection | 0      | train\n5 | res_blocks      | ModuleList       | 39.4 K | train\n-------------------------------------------------------------\n39.4 K    Trainable params\n0         Non-trainable params\n39.4 K    Total params\n0.157     Total estimated model params size (MB)\n28        Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83c\udfcb\ufe0f Treinando com dados at\u00e9 2025-01-01...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a334600d4d4e11aba88f47f20fc352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:49:38 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udcbe Registrando modelo como: ds_dev.cvc.loja_TCN\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8ec2c77a264f9493b3192c781e3563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026/01/15 12:49:38 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"n\"\n    ],\n    \"data\": [\n      [\n        35\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: A load persistent id instruction was encountered, but no persistent_load function was specified.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58957e26bb144e2bd1c9cd8f1e022c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'ds_dev.cvc.loja_TCN' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433655e4d26c4df5a90f5775324f7ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '7' of model 'ds_dev.cvc.loja_tcn'.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   \ud83d\udd2e Iniciando Infer\u00eancia Walk-Forward (5 folds)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c62305e5d74704966c203cfd7881a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-01: SMAPE=142.11%, RMSE=3422.63\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b089df24306142c2892de99aace98d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-02: SMAPE=172.69%, RMSE=1576.20\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be9ec20aa7549819f4dadb2a52d143c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-03: SMAPE=200.00%, RMSE=9240.84\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ab29f653fc4ed7ab670e860a766f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-04: SMAPE=200.00%, RMSE=12944.18\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2abf7e4383e4d7cb7e1399d60974373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     \ud83d\udcc5 2025-05: SMAPE=166.75%, RMSE=7710.85\n   \ud83d\udcca GLOBAL: MAPE=inf%, RMSE=8172.27\n\u2705 Processo Finalizado.\n"
     ]
    }
   ],
   "source": [
    "# --- EXECU\u00c7\u00c3O DO PIPELINE (OTIMIZADO COM FEATURE STORE) ---\n",
    "print(f\"\ud83d\ude80 Iniciando Pipeline v{config.VERSION} (Walk-Forward Strict Mode)\")\n",
    "\n",
    "ingestion = DataIngestion(spark, config)\n",
    "\n",
    "# No bloco de execu\u00e7\u00e3o:\n",
    "# 1. Busca Unificada (Feature Store + Spark ETL)\n",
    "df_spark_wide = ingestion.create_training_set() # Retorna Spark DF\n",
    "df_support_global = ingestion.get_global_support() # Retorna Pandas (pois \u00e9 pequeno)\n",
    "\n",
    "# 2. Constru\u00e7\u00e3o dos Objetos Darts (Aqui ocorre o toPandas)\n",
    "raw_series, raw_covs = ingestion.build_darts_objects(df_spark_wide, df_support_global)\n",
    "\n",
    "# --- Daqui para baixo, o c\u00f3digo original de treino se mant\u00e9m igual ---\n",
    "# 3. SPLIT DE TREINO\n",
    "train_cutoff_date = pd.Timestamp(config.TRAIN_END_DATE) - pd.Timedelta(days=1)\n",
    "print(f\"\u2702\ufe0f Data corte para treino est\u00e1tico: {train_cutoff_date.date()}\")\n",
    "\n",
    "print(\"\ud83d\udee0\ufe0f Ajustando Pipeline (Scalers)...\")\n",
    "project_pipeline = ProjectPipeline()\n",
    "\n",
    "train_for_fit = [s.drop_after(train_cutoff_date) for s in raw_series]\n",
    "cov_for_fit = [s.drop_after(train_cutoff_date) for s in raw_covs]\n",
    "project_pipeline.fit(train_for_fit, cov_for_fit)\n",
    "\n",
    "print(\"\ud83d\udd04 Transformando TODAS as s\u00e9ries...\")\n",
    "series_scaled_full, cov_scaled_full = project_pipeline.transform(raw_series, raw_covs)\n",
    "\n",
    "# Salvar Pipeline\n",
    "pipeline_path = f\"{config.PATH_SCALERS}/project_pipeline_v{config.VERSION}.pkl\"\n",
    "with open(pipeline_path, 'wb') as f:\n",
    "    pickle.dump(project_pipeline, f)\n",
    "print(f\"\ud83d\udcbe Pipeline salvo: {pipeline_path}\")\n",
    "\n",
    "# Filtragem de S\u00e9ries Curtas e Sets Finais\n",
    "print(\"\ud83d\udd0d Filtrando s\u00e9ries curtas...\")\n",
    "min_len = config.LAGS + config.FORECAST_HORIZON + 1\n",
    "valid_indices = [i for i, ts in enumerate(train_for_fit) if len(ts) >= min_len]\n",
    "\n",
    "train_series_static = [series_scaled_full[i].drop_after(train_cutoff_date) for i in valid_indices]\n",
    "train_cov_static = [cov_scaled_full[i].drop_after(train_cutoff_date) for i in valid_indices]\n",
    "full_series_valid = [series_scaled_full[i] for i in valid_indices]\n",
    "full_cov_valid = [cov_scaled_full[i] for i in valid_indices]\n",
    "\n",
    "print(\"\ud83d\udd04 Preparando targets originais para valida\u00e7\u00e3o...\")\n",
    "val_series_original = project_pipeline.inverse_transform(full_series_valid, partial=True)\n",
    "\n",
    "# 4. CONFIGURA\u00c7\u00c3O DE MODELOS\n",
    "lag = config.LAGS\n",
    "lag_covariantes = config.LAGS_FUTURE\n",
    "forecast = config.FORECAST_HORIZON\n",
    "lag_2 = lag + config.FORECAST_HORIZON # Lag estendido para Deep Learning\n",
    "dynamic_kernel = 3 # Kernel safe size\n",
    "EARLY_STOPPER = EarlyStopping(monitor=\"train_loss\", patience=5, min_delta=0.001, mode='min')\n",
    "\n",
    "models_dict = {\n",
    "    # --- MODELOS ESTAT\u00cdSTICOS / ML CL\u00c1SSICO ---\n",
    "    \"LinearRegression\": LinearRegressionModel(\n",
    "        lags=lag,\n",
    "        lags_future_covariates=lag_covariantes,\n",
    "        output_chunk_length=forecast,\n",
    "        multi_models=True\n",
    "    ),\n",
    "    \"RandomForest\": RandomForest(\n",
    "        lags=lag,\n",
    "        lags_future_covariates=lag_covariantes,\n",
    "        output_chunk_length=forecast,\n",
    "        multi_models=False, # RF sklearn limita\u00e7\u00e3o\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LightGBM\": LightGBMModel(\n",
    "        lags=lag,\n",
    "        lags_future_covariates=lag_covariantes,\n",
    "        output_chunk_length=forecast,\n",
    "        multi_models=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"XGBoost\": XGBModel(\n",
    "        lags=lag,\n",
    "        lags_future_covariates=lag_covariantes,\n",
    "        output_chunk_length=forecast,\n",
    "        multi_models=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"CatBoost\": CatBoostModel(\n",
    "        lags=lag,\n",
    "        lags_future_covariates=lag_covariantes,\n",
    "        output_chunk_length=forecast,\n",
    "        multi_models=True,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# --- MODELOS DE DEEP LEARNING (Adicionados se N_EPOCHS > 0) ---\n",
    "if config.N_EPOCHS > 0:\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"cpu\", \"callbacks\": [EARLY_STOPPER]}\n",
    "    models_dict.update({\n",
    "        \"TFT\": TFTModel(\n",
    "            input_chunk_length=lag_2,\n",
    "            output_chunk_length=forecast,\n",
    "            hidden_size=128,\n",
    "            lstm_layers=2,\n",
    "            num_attention_heads=4,\n",
    "            dropout=0.2,\n",
    "            batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS,\n",
    "            add_relative_index=True,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"NBEATS\": NBEATSModel(\n",
    "            input_chunk_length=lag_2,\n",
    "            output_chunk_length=forecast,\n",
    "            generic_architecture=True,\n",
    "            num_stacks=3,\n",
    "            num_blocks=3,\n",
    "            num_layers=4,\n",
    "            layer_widths=256,\n",
    "            batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"Transformer\": TransformerModel(\n",
    "            input_chunk_length=lag_2,\n",
    "            output_chunk_length=forecast,\n",
    "            d_model=128,\n",
    "            nhead=4,\n",
    "            num_encoder_layers=3,\n",
    "            num_decoder_layers=3,\n",
    "            dim_feedforward=256,\n",
    "            dropout=0.2,\n",
    "            batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"BlockRNN\": BlockRNNModel(\n",
    "            model='LSTM',\n",
    "            input_chunk_length=lag_2,\n",
    "            output_chunk_length=forecast,\n",
    "            hidden_dim=128,\n",
    "            n_rnn_layers=2,\n",
    "            dropout=0.2,\n",
    "            batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"TCN\": TCNModel(\n",
    "            input_chunk_length=lag_2,\n",
    "            output_chunk_length=forecast,\n",
    "            kernel_size=dynamic_kernel,\n",
    "            num_filters=lag_2,\n",
    "            num_layers=None,\n",
    "            dilation_base=2,\n",
    "            dropout=0.2,\n",
    "            batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        )\n",
    "    })\n",
    "\n",
    "trainer = ModelTrainer(config, models_dict)\n",
    "trainer.train_evaluate_walkforward(\n",
    "    train_series_static=train_series_static,\n",
    "    train_covs_static=train_cov_static,\n",
    "    full_series_scaled=full_series_valid,\n",
    "    full_covariates_scaled=full_cov_valid,\n",
    "    val_series_original=val_series_original,\n",
    "    target_pipeline=project_pipeline\n",
    ")\n",
    "print(\"\u2705 Processo Finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4,
    "widgetLayout": []
   },
   "notebookName": "cvc_validacao_modelos_lojas",
   "widgets": {
    "catalog": {
     "currentValue": "ds_dev",
     "nuid": "29272a53-8157-4b92-aac7-7fc5f0bcf225",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ds_dev",
      "label": "4. Cat\u00e1logo",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ds_dev",
      "label": "4. Cat\u00e1logo",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_treino": {
     "currentValue": "2025-01-01",
     "nuid": "9c57231a-8bfd-42dc-9982-58ae90e52eae",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_validacao": {
     "currentValue": "2025-05-31",
     "nuid": "eba7ab02-00ae-4b85-9614-72adca31086a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida\u00e7\u00e3o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-12-31",
      "label": "3. Fim Valida\u00e7\u00e3o (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_inicio_treino": {
     "currentValue": "2024-10-01",
     "nuid": "bca3de28-8ed0-48fb-9743-a6436500f256",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2019-01-01",
      "label": "1. In\u00edcio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2019-01-01",
      "label": "1. In\u00edcio Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "forecast_horizon": {
     "currentValue": "35",
     "nuid": "7aa7ecb8-dfb6-4055-953f-49ca4ad20576",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "lags": {
     "currentValue": "5",
     "nuid": "b5d1dfdd-fdcf-4649-a76c-20f30747489d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "n_epochs": {
     "currentValue": "20",
     "nuid": "9b95a973-2056-45d5-ad25-b42f6e98255a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "20",
      "label": "6. \u00c9pocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "20",
      "label": "6. \u00c9pocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}