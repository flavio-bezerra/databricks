{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8da14e6-1b34-43cb-8370-595705ffa6c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83D\uDCCA Validação de Modelos de Séries Temporais - CVC Lojas\n",
    "\n",
    "## \uD83C\uDFAF Objetivo Executivo\n",
    "Este notebook tem como objetivo realizar a **validação robusta (Backtesting)** de múltiplos algoritmos de previsão de vendas para as lojas da CVC. O processo simula cenários reais do passado para garantir que o modelo escolhido tenha performance consistente ao longo do tempo, e não apenas em um único período de teste.\n",
    "\n",
    "## \uD83D\uDEE0️ Metodologia: Walk-Forward Validation (Strict Mode)\n",
    "Diferente da divisão tradicional (Treino/Teste), utilizamos a estratégia de **Walk-Forward** (Janela Deslizante):\n",
    "1.  O modelo treina com dados até uma data de corte (ex: Dez/2024).\n",
    "2.  Faz a previsão para o mês seguinte (ex: Jan/2025).\n",
    "3.  A janela avança 1 mês, o modelo retreina com os dados reais de Jan/2025 e prevê Fev/2025.\n",
    "4.  Isso se repete por 12 meses (Folds), gerando métricas de erro (RMSE, SMAPE) para cada mês.\n",
    "\n",
    "> **Nota:** O modo \"Strict\" garante que **nenhum dado do futuro** (vazamento de dados) seja acessível ao modelo durante o treino, simulando fielmente a produção.\n",
    "\n",
    "---\n",
    "\n",
    "## \uD83E\uDD16 Estratégia de Modelos (Model)\n",
    "A pipeline avalia automaticamente duas classes de algoritmos via biblioteca **Darts**:\n",
    "\n",
    "### 1. Machine Learning Clássico (Regressores)\n",
    "* **Linear Regression:** Baseline simples para capturar tendências lineares.\n",
    "* **Random Forest:** Captura não-linearidades e interações complexas.\n",
    "* **LightGBM / XGBoost / CatBoost:** Modelos baseados em *Gradient Boosting*, estado da arte para dados tabulares e séries temporais com covariáveis.\n",
    "\n",
    "### 2. Deep Learning (SOTA - State of the Art)\n",
    "* **TFT (Temporal Fusion Transformer):** Modelo de atenção que aprende a importância de cada variável ao longo do tempo.\n",
    "* **N-BEATS:** Rede neural baseada em blocos de tendência e sazonalidade.\n",
    "* **Transformer:** Arquitetura clássica de *Attention* adaptada para séries temporais.\n",
    "* **BlockRNN (LSTM):** Redes recorrentes para capturar dependências de longo prazo.\n",
    "* **TCN (Temporal Convolutional Network):** Convoluções causais para capturar padrões locais e globais.\n",
    "\n",
    "---\n",
    "\n",
    "## \uD83C\uDFDB️ Arquitetura e Governança (Databricks Unity Catalog)\n",
    "Este notebook implementa uma arquitetura híbrida para conformidade com o Unity Catalog:\n",
    "\n",
    "| Componente | Local de Armazenamento | Função |\n",
    "| :--- | :--- | :--- |\n",
    "| **Experimentos** | `Workspace/Users/...` | Armazena métricas, gráficos e logs de execução (evita erro de path do UC). |\n",
    "| **Registro de Modelos** | **Unity Catalog** (`ds_dev.cvc_val`) | O modelo final (`.pkl`) é versionado e governado oficialmente no catálogo. |\n",
    "| **Assinatura (Signature)** | **Enforced** | Todos os modelos possuem contrato de entrada/saída (`long` -> `double`) validado para evitar erros de tipagem no serving. |\n",
    "\n",
    "## \uD83D\uDCE5 Dados de Entrada\n",
    "* **Target:** `bip_vhistorico_targuet_loja` (Vendas históricas).\n",
    "* **Covariáveis Futuras:** `bip_vhistorico_feriados_loja` (Calendário nacional/regional).\n",
    "* **Covariáveis Globais:** `bip_vhistorico_suporte_canal_loja` (Indicadores macroeconômicos e campanhas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c73be932-bbbc-4f6f-ad37-d46f95b893d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "import mlflow.sklearn\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "# Darts Imports\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.pipeline import Pipeline\n",
    "from darts.dataprocessing.transformers import (\n",
    "    Scaler,\n",
    "    StaticCovariatesTransformer,\n",
    "    MissingValuesFiller\n",
    ")\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.models import (\n",
    "    TFTModel,\n",
    "    NBEATSModel,\n",
    "    TransformerModel,\n",
    "    LinearRegressionModel,\n",
    "    LightGBMModel,\n",
    "    XGBModel,\n",
    "    CatBoostModel,\n",
    "    RandomForest,\n",
    "    BlockRNNModel,\n",
    "    RNNModel,\n",
    "    TCNModel\n",
    ")\n",
    "from darts.metrics import mape, mse, rmse, r2_score, smape\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# Configuração do Ambiente\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "# Obtém Spark Session\n",
    "try:\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "except NameError:\n",
    "    spark = None # Lidar com isso se rodar fora do spark\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05909cbb-4d23-4d4e-a1a1-2bda8123c4ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. CONFIGURAÇÃO (SINGLETON) ---\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Tenta pegar widgets do Databricks\n",
    "        try:\n",
    "            from pyspark.dbutils import DBUtils\n",
    "            dbutils = DBUtils(spark)\n",
    "        except ImportError:\n",
    "            dbutils = None\n",
    "\n",
    "        try:\n",
    "            # Setup Widgets se não existirem\n",
    "            try:\n",
    "                dbutils.widgets.text(\"data_inicio_treino\", \"2019-01-01\", \"1. Início Treino\")\n",
    "                dbutils.widgets.text(\"data_fim_treino\", \"2025-01-01\", \"2. Fim Treino (Corte)\")\n",
    "                dbutils.widgets.text(\"data_fim_validacao\", \"2025-12-31\", \"3. Fim Validação (Ground Truth)\")\n",
    "                dbutils.widgets.text(\"catalog\", \"ds_dev\", \"4. Catálogo\")\n",
    "                dbutils.widgets.text(\"forecast_horizon\", \"35\", \"5. Horizonte (Dias)\")\n",
    "                dbutils.widgets.text(\"n_epochs\", \"20\", \"6. Épocas (DL Models)\")\n",
    "                dbutils.widgets.text(\"lags\", \"5\", \"7. Lags\")\n",
    "            except:\n",
    "                pass # Widgets já criados ou erro ao criar\n",
    "\n",
    "            self.CATALOG = dbutils.widgets.get(\"catalog\")\n",
    "            self.DATA_START = dbutils.widgets.get(\"data_inicio_treino\")\n",
    "            # TRAIN_END_DATE: Data limite para o modelo APRENDER (Fit).\n",
    "            self.TRAIN_END_DATE = dbutils.widgets.get(\"data_fim_treino\")\n",
    "            # INGESTION_END: Data limite para carregar dados (precisa incluir 2025 para validar)\n",
    "            self.INGESTION_END = dbutils.widgets.get(\"data_fim_validacao\")\n",
    "            self.VAL_START_DATE = self.TRAIN_END_DATE                               # Validação começa onde treino termina\n",
    "            self.FORECAST_HORIZON = int(dbutils.widgets.get(\"forecast_horizon\"))\n",
    "            self.N_EPOCHS = int(dbutils.widgets.get(\"n_epochs\"))\n",
    "            self.LAGS = int(dbutils.widgets.get(\"lags\"))\n",
    "        except (NameError, Exception):\n",
    "            print('⚠️ Célula rodando fora do contexto de Widgets do Databricks/dbutils.')\n",
    "\n",
    "        self.SCHEMA = \"cvc_val\"\n",
    "        # Unity Catalog Volumes Path\n",
    "        self.VOLUME_ROOT = f\"/Volumes/{self.CATALOG}/{self.SCHEMA}/experiments/artefacts/loja\"\n",
    "        self.PATH_SCALERS = f\"{self.VOLUME_ROOT}/scalar/validation\"\n",
    "        self.PATH_MODELS = f\"{self.VOLUME_ROOT}/models/validation\"\n",
    "        \n",
    "        # DEFINIÇÃO DO EXPERIMENTO MLFLOW\n",
    "        self.EXPERIMENT_NAME = \"/Workspace/Shared/data_science/projetos/cvc_curva_de_vendas_por_canal/experiments/Model_Validation_CVC_Loja\"\n",
    "        self.MLFLOW_REGISTRY_URI = \"databricks-uc\"\n",
    "        self.LAGS_FUTURE = [0, -1, -2, -3]\n",
    "        self.VERSION = datetime.now(pytz.timezone('America/Sao_Paulo')).strftime('%Y_%m_%d_%H_%M')\n",
    "\n",
    "        # Garante estrutura de diretórios\n",
    "        for path in [self.PATH_SCALERS, self.PATH_MODELS]:\n",
    "            os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "685e48fe-765a-4c3f-b9d8-52aa2e780326",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 2. INGESTÃO DE DADOS (ETL NO SPARK - SCALABLE) ---\n",
    "from databricks.feature_engineering import FeatureEngineeringClient, FeatureLookup\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, spark_session, config):\n",
    "        self.spark = spark_session\n",
    "        self.config = config\n",
    "        self.fe = FeatureEngineeringClient()\n",
    "\n",
    "    def create_training_set(self):\n",
    "        \"\"\"\n",
    "        Gera o dataset completo via Feature Store e realiza ETL nativo no Spark.\n",
    "        Retorna: DataFrame PySpark (Lazy Evaluation)\n",
    "        \"\"\"\n",
    "        print(\"\uD83D\uDED2 Construindo Training Set via Feature Store (Spark Native)...\")\n",
    "\n",
    "        # 1. Definir a 'Spine' (Target)\n",
    "        target_table = f\"{self.config.CATALOG}.{self.config.SCHEMA}.bip_vhistorico_targuet_loja\"\n",
    "        \n",
    "        df_spine = (self.spark.table(target_table)\n",
    "                    .filter(F.col(\"DATA\").between(self.config.DATA_START, self.config.INGESTION_END))\n",
    "                    .select(\"CODIGO_LOJA\", \"DATA\", \"VALOR\")\n",
    "                    .withColumnRenamed(\"VALOR\", \"TARGET_VENDAS\")\n",
    "                    .withColumn(\"CODIGO_LOJA\", F.col(\"CODIGO_LOJA\").cast(\"string\"))\n",
    "                   )\n",
    "\n",
    "        # 2. Configurar Lookups\n",
    "        feature_lookups = [\n",
    "            FeatureLookup(\n",
    "                table_name=f\"{self.config.CATALOG}.{self.config.SCHEMA}.cmc_alojas\",\n",
    "                lookup_key=[\"CODIGO_LOJA\"],\n",
    "                feature_names=[\"CLUSTER_LOJA\", \"SIGLA_UF\", \"TIPO_LOJA\", \"MODELO_LOJA\"]\n",
    "            ),\n",
    "            FeatureLookup(\n",
    "                table_name=f\"{self.config.CATALOG}.{self.config.SCHEMA}.bip_vhistorico_feriados_loja\",\n",
    "                lookup_key=[\"CODIGO_LOJA\"],\n",
    "                timestamp_lookup_key=\"DATA\",\n",
    "                feature_names=[\"VALOR\"], \n",
    "                output_name=\"IS_FERIADO\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 3. Criar Training Set (Retorna objeto FeatureEngineeringTrainingSet)\n",
    "        training_set = self.fe.create_training_set(\n",
    "            df=df_spine,\n",
    "            feature_lookups=feature_lookups,\n",
    "            label=\"TARGET_VENDAS\",\n",
    "            exclude_columns=[]\n",
    "        )\n",
    "\n",
    "        # 4. Carregar como DataFrame Spark (SEM toPandas aqui)\n",
    "        df_spark = training_set.load_df()\n",
    "\n",
    "        # --- ETL NATIVO NO SPARK (Distribuído) ---\n",
    "        print(\"   ⚡ Executando limpeza e tratamento no Spark Cluster...\")\n",
    "        \n",
    "        # A. Tratamento de Nulos (Left Joins geram nulos)\n",
    "        # Sintaxe Spark: fill(valor, subset=[colunas]) ou fill({col: val})\n",
    "        df_spark = df_spark.na.fill({\n",
    "            \"IS_FERIADO\": 0.0, \n",
    "            \"TARGET_VENDAS\": 0.0,\n",
    "            \"CLUSTER_LOJA\": \"DESCONHECIDO\",\n",
    "            \"SIGLA_UF\": \"DESCONHECIDO\",\n",
    "            \"TIPO_LOJA\": \"DESCONHECIDO\",\n",
    "            \"MODELO_LOJA\": \"DESCONHECIDO\"\n",
    "        })\n",
    "\n",
    "        # B. Garantia de Tipos (Casting)\n",
    "        df_spark = df_spark.withColumn(\"DATA\", F.to_timestamp(\"DATA\"))\n",
    "        \n",
    "        return df_spark\n",
    "\n",
    "    def get_global_support(self):\n",
    "        \"\"\"\n",
    "        Carrega suporte global mantendo processamento no Spark até o final.\n",
    "        \"\"\"\n",
    "        table_name = \"bip_vhistorico_suporte_canal_loja\"\n",
    "        print(f\"\uD83C\uDF0D Carregando suporte global (Spark Aggregation)...\")\n",
    "        \n",
    "        # Toda a agregação ocorre no cluster\n",
    "        df_spark = (self.spark.table(f\"{self.config.CATALOG}.{self.config.SCHEMA}.{table_name}\")\n",
    "            .filter(F.col(\"DATA\").between(self.config.DATA_START, self.config.INGESTION_END))\n",
    "            .groupBy(\"DATA\")\n",
    "            .pivot(\"METRICAS\")\n",
    "            .agg(F.sum(\"VALOR\"))\n",
    "            .na.fill(0.0) # Preenche nulos do pivot no Spark\n",
    "        )\n",
    "        \n",
    "        # Só converte o resultado final (pequeno) para Pandas\n",
    "        pdf = df_spark.toPandas()\n",
    "        pdf['DATA'] = pd.to_datetime(pdf['DATA'])\n",
    "        return pdf.set_index('DATA').asfreq('D').fillna(0.0)\n",
    "\n",
    "    def build_darts_objects(self, df_spark_wide, df_global_support):\n",
    "        \"\"\"\n",
    "        Recebe Spark DataFrame -> Converte para Pandas -> Cria objetos Darts\n",
    "        \"\"\"\n",
    "        print(\"⚙️ Materializando dados do Spark para Pandas (Driver)...\")\n",
    "        \n",
    "        # AQUI acontece a transferência de dados Cluster -> Driver\n",
    "        # Como já filtramos e limpamos no Spark, o dado vem menor e mais limpo.\n",
    "        df_wide = df_spark_wide.toPandas()\n",
    "        \n",
    "        # Garante tipos Pandas compatíveis com Darts\n",
    "        df_wide['DATA'] = pd.to_datetime(df_wide['DATA'])\n",
    "        \n",
    "        # Identificação dinâmica de colunas estáticas\n",
    "        possible_static = [\"CLUSTER_LOJA\", \"SIGLA_UF\", \"TIPO_LOJA\", \"MODELO_LOJA\"]\n",
    "        static_cols = [c for c in possible_static if c in df_wide.columns]\n",
    "\n",
    "        print(\"   Build: Criando Target Series...\")\n",
    "        target_series_list = TimeSeries.from_group_dataframe(\n",
    "            df_wide,\n",
    "            group_cols=\"CODIGO_LOJA\",\n",
    "            time_col=\"DATA\",\n",
    "            value_cols=\"TARGET_VENDAS\",\n",
    "            static_cols=static_cols,\n",
    "            freq='D',\n",
    "            fill_missing_dates=True,\n",
    "            fillna_value=0.0\n",
    "        )\n",
    "        \n",
    "        target_dict = {str(ts.static_covariates.index[0]): ts for ts in target_series_list}\n",
    "        valid_stores = list(target_dict.keys())\n",
    "\n",
    "        print(\"   Build: Criando Covariáveis Locais...\")\n",
    "        feriado_series_list = TimeSeries.from_group_dataframe(\n",
    "            df_wide,\n",
    "            group_cols=\"CODIGO_LOJA\",\n",
    "            time_col=\"DATA\",\n",
    "            value_cols=[\"IS_FERIADO\"], \n",
    "            freq='D',\n",
    "            fill_missing_dates=True,\n",
    "            fillna_value=0.0\n",
    "        )\n",
    "        feriado_dict = {str(ts.static_covariates[\"CODIGO_LOJA\"].iloc[0]): ts for ts in feriado_series_list}\n",
    "\n",
    "        # Globais (já vieram prontas do método get_global_support)\n",
    "        ts_support = TimeSeries.from_dataframe(\n",
    "            df_global_support, \n",
    "            fill_missing_dates=True, \n",
    "            freq='D',\n",
    "            fillna_value=0.0\n",
    "        )\n",
    "        \n",
    "        ts_time = datetime_attribute_timeseries(df_global_support.index, attribute=\"dayofweek\", cyclic=True)\n",
    "        ts_time = ts_time.stack(datetime_attribute_timeseries(df_global_support.index, attribute=\"quarter\", one_hot=True))\n",
    "        ts_time = ts_time.stack(datetime_attribute_timeseries(df_global_support.index, attribute=\"week\", cyclic=True))\n",
    "        \n",
    "        global_covariates = ts_support.stack(ts_time)\n",
    "\n",
    "        final_target_list = []\n",
    "        full_covariates_list = []\n",
    "\n",
    "        print(\"   Build: Stacking Final...\")\n",
    "        for loja in valid_stores:\n",
    "            ts_target = target_dict[loja]\n",
    "            final_target_list.append(ts_target)\n",
    "            \n",
    "            ts_local = feriado_dict.get(loja)\n",
    "            if ts_local:\n",
    "                 ts_local = ts_local.slice_intersect(ts_target)\n",
    "            else:\n",
    "                 ts_local = TimeSeries.from_times_and_values(ts_target.time_index, np.zeros(len(ts_target)), freq='D')\n",
    "            \n",
    "            ts_global = global_covariates.slice_intersect(ts_target)\n",
    "            full_covariates_list.append(ts_global.stack(ts_local))\n",
    "\n",
    "        print(f\"✅ Objetos Darts Prontos: {len(final_target_list)} lojas.\")\n",
    "        return final_target_list, full_covariates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c99bff81-5076-4549-9349-f18ed5d39ac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 3. FEATURE ENGINEERING (UNIFIED PIPELINE) ---\n",
    "class ProjectPipeline:\n",
    "    def __init__(self):\n",
    "        self.target_pipeline = Pipeline([\n",
    "            MissingValuesFiller(verbose=False),\n",
    "            Scaler(name=\"target_scaler\")\n",
    "        ])\n",
    "        self.static_pipeline = Pipeline([\n",
    "            StaticCovariatesTransformer(verbose=False)\n",
    "        ])\n",
    "        self.covariate_pipeline = Pipeline([\n",
    "            MissingValuesFiller(verbose=False),\n",
    "            Scaler(name=\"covar_scaler\")\n",
    "        ])\n",
    "\n",
    "    def fit(self, target_series, covariates):\n",
    "        self.target_pipeline.fit(target_series)\n",
    "        self.static_pipeline.fit(target_series) \n",
    "        self.covariate_pipeline.fit(covariates)\n",
    "        return self\n",
    "\n",
    "    def transform(self, target_series, covariates):\n",
    "        ts_scaled = self.target_pipeline.transform(target_series)\n",
    "        ts_scaled = self.static_pipeline.transform(ts_scaled)\n",
    "        cov_scaled = self.covariate_pipeline.transform(covariates)\n",
    "        return ts_scaled, cov_scaled\n",
    "\n",
    "    def inverse_transform(self, target_series, partial=False):\n",
    "        return self.target_pipeline.inverse_transform(target_series, partial=partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cbdb955-5efb-4c4f-abcf-cdd8cbdd4c53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n  color_warning(\n"
     ]
    }
   ],
   "source": [
    "# --- 4. MODEL TRAINING MANAGER (Walk-Forward V2 - Enriched Logging) ---\n",
    "class DartsWrapper(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"\n",
    "    Wrapper melhorado para suportar inferencia com covariaveis globais.\n",
    "    \"\"\"\n",
    "    def load_context(self, context):\n",
    "        import pickle\n",
    "        with open(context.artifacts[\"darts_model\"], \"rb\") as f:\n",
    "            self.model = pickle.load(f)\n",
    "        \n",
    "        self.future_covariates = None\n",
    "        if \"future_covariates\" in context.artifacts:\n",
    "            try:\n",
    "                with open(context.artifacts[\"future_covariates\"], \"rb\") as f:\n",
    "                    self.future_covariates = pickle.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ [Wrapper] Erro ao carregar covariáveis: {e}\")\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        n = 1\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            if 'n' in model_input.columns:\n",
    "                try:\n",
    "                    n = int(model_input.iloc[0]['n'])\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        predict_kwargs = {\"n\": n}\n",
    "        if self.model.supports_future_covariates and self.future_covariates is not None:\n",
    "             predict_kwargs[\"future_covariates\"] = self.future_covariates\n",
    "\n",
    "        try:\n",
    "            pred = self.model.predict(**predict_kwargs)\n",
    "            if isinstance(pred, list):\n",
    "                 return pd.concat([p.pd_dataframe() for p in pred])\n",
    "            return pred.pd_dataframe()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ [Wrapper] Falha na predição: {str(e)}. Retornando Dummy.\")\n",
    "            dates = pd.date_range(start=\"2025-01-01\", periods=n, freq=\"D\")\n",
    "            return pd.DataFrame(np.zeros((n, 1)), index=dates, columns=[\"dummy_prediction\"])\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config, models_dict):\n",
    "        self.config = config\n",
    "        self.models = models_dict\n",
    "        self.success_models = []\n",
    "        self.failed_models = []\n",
    "\n",
    "    def _get_store_ids(self, series_list):\n",
    "        \"\"\"Extrai IDs das lojas das TimeSeries de forma segura\"\"\"\n",
    "        ids = []\n",
    "        for ts in series_list:\n",
    "            try:\n",
    "                # Tenta pegar do índice das covariáveis estáticas (padrão Darts Group)\n",
    "                if ts.static_covariates is not None:\n",
    "                    ids.append(str(ts.static_covariates.index[0]))\n",
    "                else:\n",
    "                    ids.append(\"UNKNOWN\")\n",
    "            except:\n",
    "                ids.append(\"ERROR\")\n",
    "        return ids\n",
    "\n",
    "    def train_evaluate_walkforward(self, train_series_static, train_covs_static, full_series_scaled, full_covariates_scaled, val_series_original, target_pipeline):\n",
    "        \"\"\"\n",
    "        Executa treinamento estático (2024) e validação mensal progressiva (2025).\n",
    "        \"\"\"\n",
    "        mlflow.set_experiment(self.config.EXPERIMENT_NAME)\n",
    "        \n",
    "        # Prepara metadados das lojas\n",
    "        store_ids = self._get_store_ids(train_series_static)\n",
    "        store_ids_str = \",\".join(store_ids)\n",
    "        # Cria um hash curto para identificar o conjunto de lojas nos parâmetros\n",
    "        stores_hash = hashlib.md5(store_ids_str.encode()).hexdigest()[:8]\n",
    "\n",
    "        # Salva covariáveis completas para artefato (usado no wrapper)\n",
    "        covariates_path = f\"{self.config.VOLUME_ROOT}/temp/temp_future_covariates_v{self.config.VERSION}.pkl\"\n",
    "        with open(covariates_path, \"wb\") as f:\n",
    "            pickle.dump(full_covariates_scaled, f)\n",
    "        \n",
    "        # Datas de corte para Walk-Forward\n",
    "        validation_range = pd.date_range(start=self.config.VAL_START_DATE, end=self.config.INGESTION_END, freq='MS')\n",
    "\n",
    "        for model_name, model in self.models.items():\n",
    "            print(f\"\\n\uD83D\uDE80 [Model: {model_name}] Iniciando Processo...\")\n",
    "            model_metrics_global = {}\n",
    "            all_predictions = []\n",
    "            \n",
    "            try:\n",
    "                with mlflow.start_run(run_name=f\"{model_name}_v{self.config.VERSION}\") as run:\n",
    "                    # --- PARTE 1: LOGGING DE METADADOS RICOS ---\n",
    "                    print(f\"   \uD83D\uDCDD Registrando metadados do experimento...\")\n",
    "                    \n",
    "                    # 1. Parâmetros de Configuração Básica\n",
    "                    mlflow.log_param(\"version\", self.config.VERSION)\n",
    "                    mlflow.log_param(\"horizon\", self.config.FORECAST_HORIZON)\n",
    "                    mlflow.log_param(\"model_name\", model_name)\n",
    "                    mlflow.log_param(\"lags\", self.config.LAGS)\n",
    "                    mlflow.log_param(\"epochs\", self.config.N_EPOCHS)\n",
    "                    \n",
    "                    # 2. Intervalos de Datas (Fundamental para reprodutibilidade)\n",
    "                    mlflow.log_param(\"data_start_date\", self.config.DATA_START)\n",
    "                    mlflow.log_param(\"train_cutoff_date\", self.config.TRAIN_END_DATE)\n",
    "                    mlflow.log_param(\"validation_start\", self.config.VAL_START_DATE)\n",
    "                    mlflow.log_param(\"validation_end\", self.config.INGESTION_END)\n",
    "                    \n",
    "                    # 3. Contexto das Lojas (Dataset Info)\n",
    "                    mlflow.log_param(\"n_stores_trained\", len(store_ids))\n",
    "                    mlflow.log_param(\"stores_hash\", stores_hash)\n",
    "                    \n",
    "                    # Salva a lista completa de lojas como arquivo de texto (Artifact)\n",
    "                    mlflow.log_text(store_ids_str, \"metadata/trained_store_ids.txt\")\n",
    "                    \n",
    "                    # 4. Hiperparâmetros do Modelo Específico\n",
    "                    if hasattr(model, 'model_params'):\n",
    "                         mlflow.log_param(\"model_internal_params\", str(model.model_params)[:250])\n",
    "\n",
    "                    # --- PARTE 2: TREINAMENTO ESTÁTICO ---\n",
    "                    print(f\"   \uD83C\uDFCB️ Treinando com dados até {self.config.TRAIN_END_DATE}...\")\n",
    "                    \n",
    "                    kwargs = {}\n",
    "                    if model.supports_past_covariates:\n",
    "                        kwargs['past_covariates'] = train_covs_static\n",
    "                    if model.supports_future_covariates:\n",
    "                        kwargs['future_covariates'] = train_covs_static\n",
    "                    \n",
    "                    model.fit(train_series_static, **kwargs)\n",
    "                    \n",
    "                    # Salvar Modelo e Registrar no MLflow (Estado Base)\n",
    "                    filename = f\"{model_name}_v{self.config.VERSION}.pkl\"\n",
    "                    local_path = f\"{self.config.PATH_MODELS}/{filename}\"\n",
    "                    model.save(local_path)                  \n",
    "\n",
    "                    # ========================================================\n",
    "                    # AQUI ESTÁ A ALTERAÇÃO PARA REGISTRAR NO UNITY CATALOG\n",
    "                    # ========================================================\n",
    "                    full_model_name = f\"{self.config.CATALOG}.{self.config.SCHEMA}.loja_{model_name}\"\n",
    "                    \n",
    "                    artifacts = {\"darts_model\": local_path}\n",
    "                    if model.supports_future_covariates:\n",
    "                        artifacts[\"future_covariates\"] = covariates_path                    \n",
    "\n",
    "                    input_schema = Schema([ColSpec(\"long\", \"n\")]) \n",
    "                    output_schema = Schema([ColSpec(\"double\", \"prediction\")])\n",
    "                    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "                    \n",
    "                    # Tags para facilitar busca visual no MLflow UI\n",
    "                    mlflow.set_tag(\"model_type\", model_name)\n",
    "                    mlflow.set_tag(\"validation_mode\", \"walk-forward-strict\")\n",
    "\n",
    "                    print(f\"   \uD83D\uDCBE Registrando modelo como: {full_model_name}\")\n",
    "                    mlflow.pyfunc.log_model(\n",
    "                        artifact_path=\"model\",\n",
    "                        python_model=DartsWrapper(),\n",
    "                        artifacts=artifacts,\n",
    "                        pip_requirements=[\"darts\", \"pandas\", \"numpy\", \"torch\", \"pytorch_lightning\"],\n",
    "                        input_example=pd.DataFrame({\"n\": [self.config.FORECAST_HORIZON]}), \n",
    "                        signature=signature,\n",
    "                        # Adiciona o registro no catálogo\n",
    "                        registered_model_name=full_model_name\n",
    "                    )\n",
    "\n",
    "                    # --- PARTE 3: INFERÊNCIA WALK-FORWARD (Mês a Mês) ---\n",
    "                    print(f\"   \uD83D\uDD2E Iniciando Inferência Walk-Forward ({len(validation_range)} folds)...\")\n",
    "                    \n",
    "                    for month_start in validation_range:\n",
    "                        context_cutoff = month_start - pd.Timedelta(days=1)\n",
    "                        metrica_mes = month_start.strftime(\"%Y-%m\")\n",
    "                        \n",
    "                        val_context_series = [s.drop_after(context_cutoff) for s in full_series_scaled]\n",
    "                        \n",
    "                        predict_kwargs = {\"n\": self.config.FORECAST_HORIZON}\n",
    "                        predict_kwargs['series'] = val_context_series\n",
    "                        \n",
    "                        if model.supports_past_covariates:\n",
    "                             val_context_covs = [c.drop_after(context_cutoff) for c in full_covariates_scaled]\n",
    "                             predict_kwargs['past_covariates'] = val_context_covs\n",
    "                        if model.supports_future_covariates:\n",
    "                             predict_kwargs['future_covariates'] = full_covariates_scaled \n",
    "                        \n",
    "                        preds_scaled = model.predict(**predict_kwargs)\n",
    "                        preds_inverse = target_pipeline.inverse_transform(preds_scaled, partial=True)\n",
    "                        \n",
    "                        metrics_month = self._calc_metrics_and_format(preds_inverse, val_series_original, metrica_mes, model_name)\n",
    "                        \n",
    "                        smape_m = metrics_month['metrics']['SMAPE']\n",
    "                        rmse_m = metrics_month['metrics']['RMSE']\n",
    "                        \n",
    "                        # Log métricas mensais\n",
    "                        mlflow.log_metric(f\"SMAPE_{metrica_mes}\", smape_m)\n",
    "                        \n",
    "                        print(f\"     \uD83D\uDCC5 {metrica_mes}: SMAPE={smape_m:.2f}%, RMSE={rmse_m:.2f}\")\n",
    "                        \n",
    "                        all_predictions.extend(metrics_month['dfs'])\n",
    "\n",
    "                    # --- PARTE 4: CONSOLIDAÇÃO ---\n",
    "                    if all_predictions:\n",
    "                        final_df = pd.concat(all_predictions)\n",
    "                        final_df['VERSAO'] = self.config.VERSION\n",
    "                        \n",
    "                        global_mape = np.mean(np.abs((final_df['REAL'] - final_df['PREVISAO']) / final_df['REAL'])) * 100\n",
    "                        global_rmse = np.sqrt(np.mean((final_df['REAL'] - final_df['PREVISAO'])**2))\n",
    "                        \n",
    "                        mlflow.log_metric(\"Global_MAPE\", global_mape)\n",
    "                        mlflow.log_metric(\"Global_RMSE\", global_rmse)\n",
    "                        \n",
    "                        print(f\"   \uD83D\uDCCA GLOBAL: MAPE={global_mape:.2f}%, RMSE={global_rmse:.2f}\")\n",
    "                        \n",
    "                        self._save_to_delta(final_df)\n",
    "                        self.success_models.append(model_name)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error training {model_name}: {e}\")\n",
    "                traceback.print_exc()\n",
    "                self.failed_models.append(model_name)\n",
    "\n",
    "    def _calc_metrics_and_format(self, preds, reals_full, metrica_mes, model_name):\n",
    "        if not isinstance(preds, list): preds = [preds]\n",
    "        if not isinstance(reals_full, list): reals_full = [reals_full]\n",
    "\n",
    "        valid_preds, valid_reals, res_dfs = [], [], []\n",
    "        \n",
    "        for ts_pred, ts_real_full in zip(preds, reals_full):\n",
    "            try:\n",
    "                ts_real_sliced = ts_real_full.slice_intersect(ts_pred)\n",
    "                valid_preds.append(ts_pred)\n",
    "                valid_reals.append(ts_real_sliced)\n",
    "                \n",
    "                res_dfs.append(pd.DataFrame({\n",
    "                    'DATA': ts_pred.time_index,\n",
    "                    'PREVISAO': ts_pred.values().flatten(),\n",
    "                    'REAL': ts_real_sliced.values().flatten(),\n",
    "                    'CODIGO_LOJA': str(ts_pred.static_covariates.index[0]) if ts_pred.static_covariates is not None else \"UNKNOWN\",\n",
    "                    'MODELO': model_name,\n",
    "                    'METRICA_MES': metrica_mes\n",
    "                }))\n",
    "            except:\n",
    "                continue \n",
    "        \n",
    "        metrics = {\"SMAPE\": 0.0, \"RMSE\": 0.0}\n",
    "        if valid_preds:\n",
    "            metrics[\"SMAPE\"] = float(np.mean(smape(valid_reals, valid_preds)))\n",
    "            metrics[\"RMSE\"] = float(np.mean(rmse(valid_reals, valid_preds)))\n",
    "            \n",
    "        return {\"metrics\": metrics, \"dfs\": res_dfs}\n",
    "\n",
    "    def _save_to_delta(self, pdf):\n",
    "        table_name = f\"{self.config.CATALOG}.{self.config.SCHEMA}.bip_vresultado_metricas_treinamento_lojas\"\n",
    "        try:\n",
    "            (self.config.spark_session.createDataFrame(pdf) \n",
    "             if hasattr(self.config, 'spark_session') else spark.createDataFrame(pdf)\n",
    "                .write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").saveAsTable(table_name))\n",
    "        except Exception as e:\n",
    "            print(f\"Save error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1043f186-666d-4f0e-8f11-891ede540dba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if spark is None:\n",
    "    raise RuntimeError(\"Spark Session not available.\")\n",
    "\n",
    "config = Config()\n",
    "config.spark_session = spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486a3118-319e-4a68-af2c-b8d94be26aac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDE80 Iniciando Pipeline v2026_01_15_09_42 (Walk-Forward Strict Mode)\n\uD83D\uDED2 Construindo Training Set via Feature Store (Spark Native)...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:42:41 WARNING databricks.ml_features.entities.feature_lookup: The output_name parameter is deprecated.  Use \"rename_outputs\".\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ⚡ Executando limpeza e tratamento no Spark Cluster...\n\uD83C\uDF0D Carregando suporte global (Spark Aggregation)...\n⚙️ Materializando dados do Spark para Pandas (Driver)...\n   Build: Criando Target Series...\n   Build: Criando Covariáveis Locais...\n   Build: Stacking Final...\n✅ Objetos Darts Prontos: 1 lojas.\n✂️ Data corte para treino estático: 2024-12-31\n\uD83D\uDEE0️ Ajustando Pipeline (Scalers)...\n\uD83D\uDD04 Transformando TODAS as séries...\n\uD83D\uDCBE Pipeline salvo: /Volumes/ds_dev/cvc/experiments/artefacts/loja/scalar/validation/project_pipeline_v2026_01_15_09_42.pkl\n\uD83D\uDD0D Filtrando séries curtas...\n\uD83D\uDD04 Preparando targets originais para validação...\n\n\uD83D\uDE80 [Model: LinearRegression] Iniciando Processo...\n   \uD83D\uDCDD Registrando metadados do experimento...\n   \uD83C\uDFCB️ Treinando com dados até 2025-01-01...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:45:51 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCBE Registrando modelo como: ds_dev.cvc.loja_LinearRegression\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bea3bccbad46539319e22c4881499c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddddc8037d2f4f2f8a92a12b9dcb4d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140f2d90c9a643e290847c4804eced67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ds_dev.cvc.loja_LinearRegression' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1953dacd1e54cd59965770827f9e0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '22' of model 'ds_dev.cvc.loja_linearregression'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDD2E Iniciando Inferência Walk-Forward (5 folds)...\n     \uD83D\uDCC5 2025-01: SMAPE=200.00%, RMSE=1188891008021282.50\n     \uD83D\uDCC5 2025-02: SMAPE=200.00%, RMSE=363331800284236.06\n     \uD83D\uDCC5 2025-03: SMAPE=200.00%, RMSE=4394207113599525.50\n     \uD83D\uDCC5 2025-04: SMAPE=200.00%, RMSE=9098643977247738.00\n     \uD83D\uDCC5 2025-05: SMAPE=200.00%, RMSE=6052933627652242.00\n   \uD83D\uDCCA GLOBAL: MAPE=inf%, RMSE=5090182958597040.00\n\n\uD83D\uDE80 [Model: RandomForest] Iniciando Processo...\n   \uD83D\uDCDD Registrando metadados do experimento...\n   \uD83C\uDFCB️ Treinando com dados até 2025-01-01...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:45:58 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCBE Registrando modelo como: ds_dev.cvc.loja_RandomForest\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4662cf830f184597922a016a511826eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5e037119914ed5871b97ae80e2a96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af376a736e0748cea202bd2f510c393d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ds_dev.cvc.loja_RandomForest' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ec076b09064b269c3e333a179f5f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '14' of model 'ds_dev.cvc.loja_randomforest'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDD2E Iniciando Inferência Walk-Forward (5 folds)...\n     \uD83D\uDCC5 2025-01: SMAPE=116.56%, RMSE=1798.33\n     \uD83D\uDCC5 2025-02: SMAPE=133.26%, RMSE=3223.38\n     \uD83D\uDCC5 2025-03: SMAPE=96.35%, RMSE=2777.61\n     \uD83D\uDCC5 2025-04: SMAPE=94.24%, RMSE=7384.77\n     \uD83D\uDCC5 2025-05: SMAPE=111.89%, RMSE=2372.42\n   \uD83D\uDCCA GLOBAL: MAPE=inf%, RMSE=4355.29\n\n\uD83D\uDE80 [Model: LightGBM] Iniciando Processo...\n   \uD83D\uDCDD Registrando metadados do experimento...\n   \uD83C\uDFCB️ Treinando com dados até 2025-01-01...\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.081850\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000023 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.081165\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000026 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.083318\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000020 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.086238\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain\n\n*** WARNING: max output size exceeded, skipping output. ***\n\nn, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000025 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.177317\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000021 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.176854\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000021 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 338\n[LightGBM] [Info] Number of data points in the train set: 52, number of used features: 77\n[LightGBM] [Info] Start training from score 0.177811\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:46:06 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCBE Registrando modelo como: ds_dev.cvc.loja_LightGBM\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1585560c108b4a009d0de3a7f3cd1aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9389d6d1c5d64c22a7080ed12294a0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb41ddf62a4a45e7a7b6b5ad6b7e2020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ds_dev.cvc.loja_LightGBM' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d1d481d5784bcc92089e7c31514104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '14' of model 'ds_dev.cvc.loja_lightgbm'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDD2E Iniciando Inferência Walk-Forward (5 folds)...\n     \uD83D\uDCC5 2025-01: SMAPE=101.51%, RMSE=1638.61\n     \uD83D\uDCC5 2025-02: SMAPE=97.22%, RMSE=1630.30\n     \uD83D\uDCC5 2025-03: SMAPE=52.19%, RMSE=1264.94\n     \uD83D\uDCC5 2025-04: SMAPE=116.66%, RMSE=7850.24\n     \uD83D\uDCC5 2025-05: SMAPE=84.25%, RMSE=1551.38\n   \uD83D\uDCCA GLOBAL: MAPE=inf%, RMSE=4140.33\n\n\uD83D\uDE80 [Model: XGBoost] Iniciando Processo...\n   \uD83D\uDCDD Registrando metadados do experimento...\n   \uD83C\uDFCB️ Treinando com dados até 2025-01-01...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:46:16 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCBE Registrando modelo como: ds_dev.cvc.loja_XGBoost\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3100f235a6644bfb8bdb6f0efdbc5515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4286b8f02e94cb798320bdf906fc167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25fccf88ae54d9fabbbd73a7609f6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ds_dev.cvc.loja_XGBoost' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3b76b13e6f438da7d56c49829c00d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '17' of model 'ds_dev.cvc.loja_xgboost'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDD2E Iniciando Inferência Walk-Forward (5 folds)...\n     \uD83D\uDCC5 2025-01: SMAPE=104.57%, RMSE=3101.59\n     \uD83D\uDCC5 2025-02: SMAPE=111.95%, RMSE=3150.04\n     \uD83D\uDCC5 2025-03: SMAPE=72.56%, RMSE=2827.61\n     \uD83D\uDCC5 2025-04: SMAPE=113.52%, RMSE=8080.54\n     \uD83D\uDCC5 2025-05: SMAPE=103.10%, RMSE=2897.66\n   \uD83D\uDCCA GLOBAL: MAPE=inf%, RMSE=4817.50\n\n\uD83D\uDE80 [Model: CatBoost] Iniciando Processo...\n   \uD83D\uDCDD Registrando metadados do experimento...\n   \uD83C\uDFCB️ Treinando com dados até 2025-01-01...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:48:01 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCBE Registrando modelo como: ds_dev.cvc.loja_CatBoost\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99db2821d97247b1835c833d96d9531d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb99a01ef554a058cb10d88c075eae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0aade23fa142a7aa2cd796c399b99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ds_dev.cvc.loja_CatBoost' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd38521baf24e91a0b1df1d9d9c46e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '9' of model 'ds_dev.cvc.loja_catboost'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDD2E Iniciando Inferência Walk-Forward (5 folds)...\n     \uD83D\uDCC5 2025-01: SMAPE=107.15%, RMSE=2533.92\n     \uD83D\uDCC5 2025-02: SMAPE=104.32%, RMSE=2131.13\n     \uD83D\uDCC5 2025-03: SMAPE=52.62%, RMSE=1209.97\n     \uD83D\uDCC5 2025-04: SMAPE=111.42%, RMSE=7889.40\n     \uD83D\uDCC5 2025-05: SMAPE=82.69%, RMSE=1396.37\n   \uD83D\uDCCA GLOBAL: MAPE=inf%, RMSE=4320.57\n\n\uD83D\uDE80 [Model: TFT] Iniciando Processo...\n   \uD83D\uDCDD Registrando metadados do experimento...\n   \uD83C\uDFCB️ Treinando com dados até 2025-01-01...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n   | Name                              | Type                             | Params | Mode \n------------------------------------------------------------------------------------------------\n0  | train_metrics                     | MetricCollection                 | 0      | train\n1  | val_metrics                       | MetricCollection                 | 0      | train\n2  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n3  | static_covariates_vsn             | _VariableSelectionNetwork        | 15.8 K | train\n4  | encoder_vsn                       | _VariableSelectionNetwork        | 583 K  | train\n5  | decoder_vsn                       | _VariableSelectionNetwork        | 247 K  | train\n6  | static_context_grn                | _GatedResidualNetwork            | 66.3 K | train\n7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 66.3 K | train\n8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 66.3 K | train\n9  | static_context_enrichment         | _GatedResidualNetwork            | 66.3 K | train\n10 | lstm_encoder                      | LSTM                             | 264 K  | train\n11 | lstm_decoder                      | LSTM                             | 264 K  | train\n12 | post_lstm_gan                     | _GateAddNorm                     | 33.3 K | train\n13 | static_enrichment_grn             | _GatedResidualNetwork            | 82.7 K | train\n14 | multihead_attn                    | _InterpretableMultiHeadAttention | 41.2 K | train\n15 | post_attn_gan                     | _GateAddNorm                     | 33.3 K | train\n16 | feed_forward_block                | _GatedResidualNetwork            | 66.3 K | train\n17 | pre_output_gan                    | _GateAddNorm                     | 33.3 K | train\n18 | output_layer                      | Linear                           | 2.2 K  | train\n------------------------------------------------------------------------------------------------\n1.9 M     Trainable params\n0         Non-trainable params\n1.9 M     Total params\n7.726     Total estimated model params size (MB)\n3004      Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4f89d6f75042fab602d29a785bafb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:48:56 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCBE Registrando modelo como: ds_dev.cvc.loja_TFT\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223e0e084f3e40d5b8acb79ecee46952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4235e05b014fb2a3276b00d2479802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:48:57 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"n\"\n    ],\n    \"data\": [\n      [\n        35\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: A load persistent id instruction was encountered, but no persistent_load function was specified.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46dc8293a004ecca9361a1118b4ba23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ds_dev.cvc.loja_TFT' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe121447384d4774a704adad1ffb7371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'ds_dev.cvc.loja_tft'.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDD2E Iniciando Inferência Walk-Forward (5 folds)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4da34cd4fa496b96e9d15c1e7443a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-01: SMAPE=127.28%, RMSE=3519.47\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3f4010597f49139325ed75aaef4ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-02: SMAPE=162.67%, RMSE=3930.39\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34930821c9d2431a93045d4b3cc834ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-03: SMAPE=108.92%, RMSE=2763.98\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52d354523894a1f969912f025b6f043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:darts.utils.data.inference_dataset:ValueError: For the given forecasting horizon `n=35`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n <= output_chunk_length` the future covariates must end at time step `2025-06-03 00:00:00`, whereas now they end at time step `2025-05-31 00:00:00`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-04: SMAPE=123.23%, RMSE=7542.82\n❌ Error training TFT: For the given forecasting horizon `n=35`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n <= output_chunk_length` the future covariates must end at time step `2025-06-03 00:00:00`, whereas now they end at time step `2025-05-31 00:00:00`.\n\n\uD83D\uDE80 [Model: NBEATS] Iniciando Processo...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n  File \"/root/.ipykernel/9536/command-710650326555544-3165449090\", line 183, in train_evaluate_walkforward\n    preds_scaled = model.predict(**predict_kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/torch.py\", line 103, in decorator\n    return decorated(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1465, in predict\n    predictions = self.predict_from_dataset(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/torch.py\", line 103, in decorator\n    return decorated(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1559, in predict_from_dataset\n    self._verify_predict_sample(input_series_dataset[0])\n                                ~~~~~~~~~~~~~~~~~~~~^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/data/inference_dataset.py\", line 711, in __getitem__\n    _, historic_future_covariate, future_covariate, _, _, _ = self.ds_future[idx]\n                                                              ~~~~~~~~~~~~~~^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/data/inference_dataset.py\", line 599, in __getitem__\n    ) = self.ds_past[idx]\n        ~~~~~~~~~~~~^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/data/inference_dataset.py\", line 418, in __getitem__\n    return self.ds[idx]\n           ~~~~~~~^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/data/inference_dataset.py\", line 291, in __getitem__\n    covariate_start, covariate_end = self._covariate_indexer(\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/utils/data/inference_dataset.py\", line 108, in _covariate_indexer\n    raise_log(\n  File \"/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/darts/logging.py\", line 132, in raise_log\n    raise exception\nValueError: For the given forecasting horizon `n=35`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n <= output_chunk_length` the future covariates must end at time step `2025-06-03 00:00:00`, whereas now they end at time step `2025-05-31 00:00:00`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCDD Registrando metadados do experimento...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name            | Type             | Params | Mode \n-------------------------------------------------------------\n0 | criterion       | MSELoss          | 0      | train\n1 | train_criterion | MSELoss          | 0      | train\n2 | val_criterion   | MSELoss          | 0      | train\n3 | train_metrics   | MetricCollection | 0      | train\n4 | val_metrics     | MetricCollection | 0      | train\n5 | stacks          | ModuleList       | 7.9 M  | train\n-------------------------------------------------------------\n7.8 M     Trainable params\n16.4 K    Non-trainable params\n7.9 M     Total params\n31.452    Total estimated model params size (MB)\n111       Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83C\uDFCB️ Treinando com dados até 2025-01-01...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200b524fe55d4accaff414a36934cf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:49:18 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCBE Registrando modelo como: ds_dev.cvc.loja_NBEATS\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4d622259e24b6f8aadfba2dcf56039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:49:19 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"n\"\n    ],\n    \"data\": [\n      [\n        35\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: A load persistent id instruction was encountered, but no persistent_load function was specified.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba8e28f3338459987862173d85f4db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ds_dev.cvc.loja_NBEATS' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9e5ad4df544546aff396fc4a5147a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'ds_dev.cvc.loja_nbeats'.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDD2E Iniciando Inferência Walk-Forward (5 folds)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14641c7827034635ba7268920652f6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-01: SMAPE=126.92%, RMSE=2948.03\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4848e6c388914dad8eecdfc03c86cc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-02: SMAPE=122.74%, RMSE=3004.73\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cceb5a8b0bc241c4881b40b03aad8f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-03: SMAPE=127.73%, RMSE=3826.65\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3a230671ec48e4b05acc13ff7e27a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-04: SMAPE=145.47%, RMSE=10060.44\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3106db2ee004fbeafd474da9716f6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-05: SMAPE=114.09%, RMSE=3050.67\n   \uD83D\uDCCA GLOBAL: MAPE=inf%, RMSE=5778.73\n\n\uD83D\uDE80 [Model: Transformer] Iniciando Processo...\n   \uD83D\uDCDD Registrando metadados do experimento...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name                | Type                | Params | Mode \n--------------------------------------------------------------------\n0 | criterion           | MSELoss             | 0      | train\n1 | train_criterion     | MSELoss             | 0      | train\n2 | val_criterion       | MSELoss             | 0      | train\n3 | train_metrics       | MetricCollection    | 0      | train\n4 | val_metrics         | MetricCollection    | 0      | train\n5 | encoder             | Linear              | 8.2 K  | train\n6 | positional_encoding | _PositionalEncoding | 0      | train\n7 | transformer         | Transformer         | 994 K  | train\n8 | decoder             | Linear              | 4.5 K  | train\n--------------------------------------------------------------------\n1.0 M     Trainable params\n0         Non-trainable params\n1.0 M     Total params\n4.028     Total estimated model params size (MB)\n88        Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83C\uDFCB️ Treinando com dados até 2025-01-01...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157670bcbf764416931d5d201e84a253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:49:26 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCBE Registrando modelo como: ds_dev.cvc.loja_Transformer\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04591dab631f49b786e192c7ec10a03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:49:27 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"n\"\n    ],\n    \"data\": [\n      [\n        35\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: A load persistent id instruction was encountered, but no persistent_load function was specified.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8d350b6c384ca8ac220b44b54fa035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ds_dev.cvc.loja_Transformer' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcf955853e84959824535d760be1fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'ds_dev.cvc.loja_transformer'.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDD2E Iniciando Inferência Walk-Forward (5 folds)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a735cc2ab7094cb0ae324bf08a7f7a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-01: SMAPE=133.75%, RMSE=2717.40\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695d19eb7cc64b1abb77de9e15fbaf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-02: SMAPE=139.96%, RMSE=2805.05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acae2ef146694f1da84a4f051fbf6259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-03: SMAPE=123.52%, RMSE=2819.38\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d657fc543ad4a8b8b41e70b51a6ed03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-04: SMAPE=134.98%, RMSE=8394.78\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ecd0ea57b946c38fb4666aa6ec7e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-05: SMAPE=121.38%, RMSE=2361.16\n   \uD83D\uDCCA GLOBAL: MAPE=inf%, RMSE=4839.26\n\n\uD83D\uDE80 [Model: BlockRNN] Iniciando Processo...\n   \uD83D\uDCDD Registrando metadados do experimento...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name            | Type             | Params | Mode \n-------------------------------------------------------------\n0 | criterion       | MSELoss          | 0      | train\n1 | train_criterion | MSELoss          | 0      | train\n2 | val_criterion   | MSELoss          | 0      | train\n3 | train_metrics   | MetricCollection | 0      | train\n4 | val_metrics     | MetricCollection | 0      | train\n5 | rnn             | LSTM             | 230 K  | train\n6 | fc              | Sequential       | 4.5 K  | train\n-------------------------------------------------------------\n235 K     Trainable params\n0         Non-trainable params\n235 K     Total params\n0.942     Total estimated model params size (MB)\n8         Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83C\uDFCB️ Treinando com dados até 2025-01-01...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0375c9a557084544bab190861a9c804d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:49:33 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCBE Registrando modelo como: ds_dev.cvc.loja_BlockRNN\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80bc2d11b224d7cb02eb3a19caf354c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:49:33 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"n\"\n    ],\n    \"data\": [\n      [\n        35\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: A load persistent id instruction was encountered, but no persistent_load function was specified.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b4b067d8634fe7bb2280f0103c2ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ds_dev.cvc.loja_BlockRNN' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914e85d7ee85413d859eaee5a0e6bb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'ds_dev.cvc.loja_blockrnn'.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDD2E Iniciando Inferência Walk-Forward (5 folds)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cda30da462241ffa0ac991c05ab937b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-01: SMAPE=70.23%, RMSE=826.44\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be9a98bd7014bef8ada41765480305f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-02: SMAPE=85.77%, RMSE=1022.56\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8541f7ff59f94de8931f8539507606f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-03: SMAPE=70.35%, RMSE=1192.15\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b166c40c634ff7a149812f6db96b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-04: SMAPE=110.37%, RMSE=7586.78\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f015ffa45a74469080c9ab728abe82d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-05: SMAPE=88.44%, RMSE=1311.85\n   \uD83D\uDCCA GLOBAL: MAPE=inf%, RMSE=3895.80\n\n\uD83D\uDE80 [Model: TCN] Iniciando Processo...\n   \uD83D\uDCDD Registrando metadados do experimento...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n\n  | Name            | Type             | Params | Mode \n-------------------------------------------------------------\n0 | criterion       | MSELoss          | 0      | train\n1 | train_criterion | MSELoss          | 0      | train\n2 | val_criterion   | MSELoss          | 0      | train\n3 | train_metrics   | MetricCollection | 0      | train\n4 | val_metrics     | MetricCollection | 0      | train\n5 | res_blocks      | ModuleList       | 39.4 K | train\n-------------------------------------------------------------\n39.4 K    Trainable params\n0         Non-trainable params\n39.4 K    Total params\n0.157     Total estimated model params size (MB)\n28        Modules in train mode\n0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83C\uDFCB️ Treinando com dados até 2025-01-01...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a334600d4d4e11aba88f47f20fc352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:49:38 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDCBE Registrando modelo como: ds_dev.cvc.loja_TCN\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8ec2c77a264f9493b3192c781e3563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/15 12:49:38 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"n\"\n    ],\n    \"data\": [\n      [\n        35\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: A load persistent id instruction was encountered, but no persistent_load function was specified.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58957e26bb144e2bd1c9cd8f1e022c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ds_dev.cvc.loja_TCN' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433655e4d26c4df5a90f5775324f7ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'ds_dev.cvc.loja_tcn'.\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \uD83D\uDD2E Iniciando Inferência Walk-Forward (5 folds)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c62305e5d74704966c203cfd7881a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-01: SMAPE=142.11%, RMSE=3422.63\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b089df24306142c2892de99aace98d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-02: SMAPE=172.69%, RMSE=1576.20\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be9ec20aa7549819f4dadb2a52d143c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-03: SMAPE=200.00%, RMSE=9240.84\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ab29f653fc4ed7ab670e860a766f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-04: SMAPE=200.00%, RMSE=12944.18\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2abf7e4383e4d7cb7e1399d60974373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \uD83D\uDCC5 2025-05: SMAPE=166.75%, RMSE=7710.85\n   \uD83D\uDCCA GLOBAL: MAPE=inf%, RMSE=8172.27\n✅ Processo Finalizado.\n"
     ]
    }
   ],
   "source": [
    "# --- EXECUÇÃO DO PIPELINE (OTIMIZADO COM FEATURE STORE) ---\n",
    "print(f\"\uD83D\uDE80 Iniciando Pipeline v{config.VERSION} (Walk-Forward Strict Mode)\")\n",
    "\n",
    "ingestion = DataIngestion(spark, config)\n",
    "\n",
    "# No bloco de execução:\n",
    "# 1. Busca Unificada (Feature Store + Spark ETL)\n",
    "df_spark_wide = ingestion.create_training_set() # Retorna Spark DF\n",
    "df_support_global = ingestion.get_global_support() # Retorna Pandas (pois é pequeno)\n",
    "\n",
    "# 2. Construção dos Objetos Darts (Aqui ocorre o toPandas)\n",
    "raw_series, raw_covs = ingestion.build_darts_objects(df_spark_wide, df_support_global)\n",
    "\n",
    "# --- Daqui para baixo, o código original de treino se mantém igual ---\n",
    "# 3. SPLIT DE TREINO\n",
    "train_cutoff_date = pd.Timestamp(config.TRAIN_END_DATE) - pd.Timedelta(days=1)\n",
    "print(f\"✂️ Data corte para treino estático: {train_cutoff_date.date()}\")\n",
    "\n",
    "print(\"\uD83D\uDEE0️ Ajustando Pipeline (Scalers)...\")\n",
    "project_pipeline = ProjectPipeline()\n",
    "\n",
    "train_for_fit = [s.drop_after(train_cutoff_date) for s in raw_series]\n",
    "cov_for_fit = [s.drop_after(train_cutoff_date) for s in raw_covs]\n",
    "project_pipeline.fit(train_for_fit, cov_for_fit)\n",
    "\n",
    "print(\"\uD83D\uDD04 Transformando TODAS as séries...\")\n",
    "series_scaled_full, cov_scaled_full = project_pipeline.transform(raw_series, raw_covs)\n",
    "\n",
    "# Salvar Pipeline\n",
    "pipeline_path = f\"{config.PATH_SCALERS}/project_pipeline_v{config.VERSION}.pkl\"\n",
    "with open(pipeline_path, 'wb') as f:\n",
    "    pickle.dump(project_pipeline, f)\n",
    "print(f\"\uD83D\uDCBE Pipeline salvo: {pipeline_path}\")\n",
    "\n",
    "# Filtragem de Séries Curtas e Sets Finais\n",
    "print(\"\uD83D\uDD0D Filtrando séries curtas...\")\n",
    "min_len = config.LAGS + config.FORECAST_HORIZON + 1\n",
    "valid_indices = [i for i, ts in enumerate(train_for_fit) if len(ts) >= min_len]\n",
    "\n",
    "train_series_static = [series_scaled_full[i].drop_after(train_cutoff_date) for i in valid_indices]\n",
    "train_cov_static = [cov_scaled_full[i].drop_after(train_cutoff_date) for i in valid_indices]\n",
    "full_series_valid = [series_scaled_full[i] for i in valid_indices]\n",
    "full_cov_valid = [cov_scaled_full[i] for i in valid_indices]\n",
    "\n",
    "print(\"\uD83D\uDD04 Preparando targets originais para validação...\")\n",
    "val_series_original = project_pipeline.inverse_transform(full_series_valid, partial=True)\n",
    "\n",
    "# 4. CONFIGURAÇÃO DE MODELOS\n",
    "lag = config.LAGS\n",
    "lag_covariantes = config.LAGS_FUTURE\n",
    "forecast = config.FORECAST_HORIZON\n",
    "lag_2 = lag + config.FORECAST_HORIZON # Lag estendido para Deep Learning\n",
    "dynamic_kernel = 3 # Kernel safe size\n",
    "EARLY_STOPPER = EarlyStopping(monitor=\"train_loss\", patience=5, min_delta=0.001, mode='min')\n",
    "\n",
    "models_dict = {\n",
    "    # --- MODELOS ESTATÍSTICOS / ML CLÁSSICO ---\n",
    "    \"LinearRegression\": LinearRegressionModel(\n",
    "        lags=lag,\n",
    "        lags_future_covariates=lag_covariantes,\n",
    "        output_chunk_length=forecast,\n",
    "        multi_models=True\n",
    "    ),\n",
    "    \"RandomForest\": RandomForest(\n",
    "        lags=lag,\n",
    "        lags_future_covariates=lag_covariantes,\n",
    "        output_chunk_length=forecast,\n",
    "        multi_models=False, # RF sklearn limitação\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LightGBM\": LightGBMModel(\n",
    "        lags=lag,\n",
    "        lags_future_covariates=lag_covariantes,\n",
    "        output_chunk_length=forecast,\n",
    "        multi_models=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"XGBoost\": XGBModel(\n",
    "        lags=lag,\n",
    "        lags_future_covariates=lag_covariantes,\n",
    "        output_chunk_length=forecast,\n",
    "        multi_models=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"CatBoost\": CatBoostModel(\n",
    "        lags=lag,\n",
    "        lags_future_covariates=lag_covariantes,\n",
    "        output_chunk_length=forecast,\n",
    "        multi_models=True,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# --- MODELOS DE DEEP LEARNING (Adicionados se N_EPOCHS > 0) ---\n",
    "if config.N_EPOCHS > 0:\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"cpu\", \"callbacks\": [EARLY_STOPPER]}\n",
    "    models_dict.update({\n",
    "        \"TFT\": TFTModel(\n",
    "            input_chunk_length=lag_2,\n",
    "            output_chunk_length=forecast,\n",
    "            hidden_size=128,\n",
    "            lstm_layers=2,\n",
    "            num_attention_heads=4,\n",
    "            dropout=0.2,\n",
    "            batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS,\n",
    "            add_relative_index=True,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"NBEATS\": NBEATSModel(\n",
    "            input_chunk_length=lag_2,\n",
    "            output_chunk_length=forecast,\n",
    "            generic_architecture=True,\n",
    "            num_stacks=3,\n",
    "            num_blocks=3,\n",
    "            num_layers=4,\n",
    "            layer_widths=256,\n",
    "            batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"Transformer\": TransformerModel(\n",
    "            input_chunk_length=lag_2,\n",
    "            output_chunk_length=forecast,\n",
    "            d_model=128,\n",
    "            nhead=4,\n",
    "            num_encoder_layers=3,\n",
    "            num_decoder_layers=3,\n",
    "            dim_feedforward=256,\n",
    "            dropout=0.2,\n",
    "            batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"BlockRNN\": BlockRNNModel(\n",
    "            model='LSTM',\n",
    "            input_chunk_length=lag_2,\n",
    "            output_chunk_length=forecast,\n",
    "            hidden_dim=128,\n",
    "            n_rnn_layers=2,\n",
    "            dropout=0.2,\n",
    "            batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        ),\n",
    "        \"TCN\": TCNModel(\n",
    "            input_chunk_length=lag_2,\n",
    "            output_chunk_length=forecast,\n",
    "            kernel_size=dynamic_kernel,\n",
    "            num_filters=lag_2,\n",
    "            num_layers=None,\n",
    "            dilation_base=2,\n",
    "            dropout=0.2,\n",
    "            batch_size=4,\n",
    "            n_epochs=config.N_EPOCHS,\n",
    "            random_state=42,\n",
    "            pl_trainer_kwargs=pl_trainer_kwargs\n",
    "        )\n",
    "    })\n",
    "\n",
    "trainer = ModelTrainer(config, models_dict)\n",
    "trainer.train_evaluate_walkforward(\n",
    "    train_series_static=train_series_static,\n",
    "    train_covs_static=train_cov_static,\n",
    "    full_series_scaled=full_series_valid,\n",
    "    full_covariates_scaled=full_cov_valid,\n",
    "    val_series_original=val_series_original,\n",
    "    target_pipeline=project_pipeline\n",
    ")\n",
    "print(\"✅ Processo Finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4,
    "widgetLayout": []
   },
   "notebookName": "cvc_validacao_modelos_lojas",
   "widgets": {
    "catalog": {
     "currentValue": "ds_dev",
     "nuid": "29272a53-8157-4b92-aac7-7fc5f0bcf225",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ds_dev",
      "label": "4. Catálogo",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ds_dev",
      "label": "4. Catálogo",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_treino": {
     "currentValue": "2025-01-01",
     "nuid": "9c57231a-8bfd-42dc-9982-58ae90e52eae",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-01-01",
      "label": "2. Fim Treino (Corte)",
      "name": "data_fim_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_fim_validacao": {
     "currentValue": "2025-05-31",
     "nuid": "eba7ab02-00ae-4b85-9614-72adca31086a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-12-31",
      "label": "3. Fim Validação (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-12-31",
      "label": "3. Fim Validação (Ground Truth)",
      "name": "data_fim_validacao",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_inicio_treino": {
     "currentValue": "2024-10-01",
     "nuid": "bca3de28-8ed0-48fb-9743-a6436500f256",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2019-01-01",
      "label": "1. Início Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2019-01-01",
      "label": "1. Início Treino",
      "name": "data_inicio_treino",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "forecast_horizon": {
     "currentValue": "35",
     "nuid": "7aa7ecb8-dfb6-4055-953f-49ca4ad20576",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "35",
      "label": "5. Horizonte (Dias)",
      "name": "forecast_horizon",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "lags": {
     "currentValue": "5",
     "nuid": "b5d1dfdd-fdcf-4649-a76c-20f30747489d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "5",
      "label": "7. Lags",
      "name": "lags",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "n_epochs": {
     "currentValue": "20",
     "nuid": "9b95a973-2056-45d5-ad25-b42f6e98255a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "20",
      "label": "6. Épocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "20",
      "label": "6. Épocas (DL Models)",
      "name": "n_epochs",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}